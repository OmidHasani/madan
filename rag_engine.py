"""
RAG (Retrieval-Augmented Generation) Engine for intelligent question answering
"""
import os
import logging
import re
from typing import List, Dict, Optional
from enum import Enum

from vector_store import VectorStore
from openai_http import create_chat_completion, OpenAIHTTPError
from troubleshooting_toc import get_section_page_range, get_code_for_page
from persian_english_glossary import PERSIAN_ENGLISH_GLOSSARY

# Ù†Ù‚Ø´Ù‡Ù” Ù¾Ø±ÙˆØ³ÛŒØ¬Ø±Ù‡Ø§ÛŒ Ø´Ù†Ø§Ø®ØªÙ‡â€ŒØ´Ø¯Ù‡ Ø¨Ù‡ Ù…Ø­Ø¯ÙˆØ¯Ù‡Ù” ØµÙØ­Ù‡ Ø¯Ø± PDF (ØµÙØ­Ù‡Ù” ÙˆØ§Ù‚Ø¹ÛŒ Ø¯Ø± metadata Ú†Ø§Ù†Ú©â€ŒÙ‡Ø§)
# ØªØ§ ÙˆÙ‚ØªÛŒ Ø³ÙˆØ§Ù„ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ø¯Ø±Ø¨Ø§Ø±Ù‡Ù” Ø§ÛŒÙ† Ù¾Ø±ÙˆØ³ÛŒØ¬Ø± Ø§Ø³ØªØŒ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ø§ ØµÙØ­Ù‡ ÙˆØ§Ø±ÛŒØ² Ú©Ù†ÛŒÙ… Ùˆ Ø¨Ù‡ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ ÙˆØ§Ø¨Ø³ØªÙ‡ Ù†Ø¨Ø§Ø´ÛŒÙ…
PROCEDURE_PAGE_MAP: List[tuple] = [
    # (Ù„ÛŒØ³Øª Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ØªØ·Ø§Ø¨Ù‚ Ø³ÙˆØ§Ù„ØŒ ØµÙØ­Ù‡Ù” Ø´Ø±ÙˆØ¹ PDFØŒ ØµÙØ­Ù‡Ù” Ù¾Ø§ÛŒØ§Ù† PDF)
    (["bleeding air from each part", "ØªØ®Ù„ÛŒÙ‡ Ù‡ÙˆØ§ Ø§Ø² Ù‡Ø± Ø¨Ø®Ø´", "air bleeding each part", "each part"], 339, 341),
    (["measuring oil leakage", "Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù†Ø´Øª Ø±ÙˆØºÙ†", "oil leakage", "measuring leakage"], 334, 337),
    # Ù…ÙˆØªÙˆØ± Ú†Ø±Ø®Ø´ÛŒ / Swing motor: Ø³Ø§Ø®ØªØ§Ø±ØŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ùˆ Ù…Ø¹ÛŒØ§Ø± Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ (Swing machinery + Swing circle) â€” PC800, 800LC-8
    (["swing motor", "Ù…ÙˆØªÙˆØ± Ú†Ø±Ø®Ø´ÛŒ", "swing circle", "Ù…ÙˆØªÙˆØ± Ø³ÙˆØ¦ÛŒÙ†Ú¯", "Ø³Ø§Ø®ØªØ§Ø± Ù…ÙˆØªÙˆØ± Ú†Ø±Ø®Ø´ÛŒ", "Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ù…ÙˆØªÙˆØ± Ú†Ø±Ø®Ø´ÛŒ"], 74, 77),
]

# ÙˆÙ‚ØªÛŒ Ú©Ø§Ø±Ø¨Ø± Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯ Â«Ù…Ø´Ú©Ù„ X Ø¯Ø§Ø±Ù…Â» / Â«X Ø®Ø±Ø§Ø¨ Ø§Ø³ØªÂ» (Ø¨Ø¯ÙˆÙ† Ø°Ú©Ø± Ú©Ø¯)ØŒ Ø§ÛŒÙ† Ú©Ø¯Ù‡Ø§ÛŒ Ø®Ø·Ø§ Ø±Ø§ Ù…Ø³ØªÙ‚ÛŒÙ… Ø§Ø² Ø§ÛŒÙ†Ø¯Ú©Ø³ Ù„ÙˆØ¯ Ú©Ù†
# ØªØ§ Ø­ØªÙ…Ø§Ù‹ Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ Ù‡Ù…Ø§Ù† Ù‚Ø·Ø¹Ù‡ Ø¨ÛŒØ§ÛŒØ¯ØŒ Ù†Ù‡ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ú©Ù‡ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú†Ø§Ù†Ú© Ø§Ø´ØªØ¨Ø§Ù‡ Ø¨ÛŒØ§ÙˆØ±Ø¯
COMPONENT_PROBLEM_TO_CODES: List[tuple] = [
    # (Ù„ÛŒØ³Øª Ø¹Ø¨Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ù‚Ø·Ø¹Ù‡ØŒ Ù„ÛŒØ³Øª Ú©Ø¯Ù‡Ø§ÛŒ Ø®Ø·Ø§ÛŒ Ù…Ø±ØªØ¨Ø·)
    (["Ø´ÛŒØ± Ø¨Ø§ÛŒ Ù¾Ø³", "Ø´ÛŒØ± Ø¨Ø§ÛŒÙ¾Ø³", "Ø¨Ø§ÛŒ Ù¾Ø³", "Ø¨Ø§ÛŒÙ¾Ø³", "bypass valve"], ["CA1626", "CA1627", "CA1628", "CA1629", "CA1631", "CA1632"]),
]
PROBLEM_MARKERS: List[str] = [
    "Ù…Ø´Ú©Ù„", "Ø®Ø±Ø§Ø¨", "Ø®Ø±Ø§Ø¨Ù‡", "Ø¹ÛŒØ¨", "Ù…Ø´Ú©Ù„ Ø¯Ø§Ø±Ù…", "Ø®Ø±Ø§Ø¨ Ø§Ø³Øª", "Ù†Ø¯Ø§Ø±Ù‡", "Ú©Ø§Ø± Ù†Ù…ÛŒÚ©Ù†Ù‡", "Ú©Ø§Ø± Ù†Ù…ÛŒâ€ŒÚ©Ù†Ù‡",
    "problem", "defective", "fault", "error",
]

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class IntentType(Enum):
    """
    Three primary question types (plus an internal UNCLEAR state).

    The user wants exactly 3 outward behaviors:
    1) error/fault/alarm â†’ HTML troubleshooting template
    2) procedure/measurement/how-to â†’ detailed step-by-step instructions (ONLY if present in docs)
    3) general/definition/overview â†’ complete explanation (ONLY if present in docs)
    """
    ERROR_FIX = "error_fix"
    PROCEDURE = "procedure"
    GENERAL = "general"
    UNCLEAR = "unclear"


class RAGEngine:
    """
    RAG engine that combines vector search with LLM generation
    for accurate question answering based on document content
    """
    
    def __init__(
        self,
        vector_store: VectorStore,
        api_key: str,
        chat_model: str = "gpt-5.2",
        temperature: float = 0,  # Lower temperature for more deterministic, complete responses
        max_tokens: int = 16000
    ):
        """
        Initialize RAG engine
        
        Args:
            vector_store: VectorStore instance for retrieval
            api_key: OpenAI API key
            chat_model: Model to use for generation
            temperature: Temperature for generation (lower = more focused)
            max_tokens: Maximum tokens in response
        """
        self.vector_store = vector_store
        self.api_key = api_key
        self.chat_model = chat_model
        self.temperature = temperature
        self.max_tokens = max_tokens
        # NOTE: We intentionally do NOT use the OpenAI Python SDK here.
        # Some environments fail during SDK initialization due to proxy/httpx issues.
        
        # Ø³ÛŒØ³ØªÙ… Ø­Ø§ÙØ¸Ù‡ Ø¨Ø±Ø§ÛŒ sessions Ù…Ø®ØªÙ„Ù
        self.conversation_memory = {}  # {session_id: [messages]}
        
        logger.info(f"RAG engine initialized with model: {chat_model}")
    
    def detect_intent(self, question: str) -> Dict:
        """
        ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ø³ÙˆØ§Ù„ Ø·Ø¨Ù‚ Û³ ØªÛŒÙ¾ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ú©Ø§Ø±Ø¨Ø±
        
        Args:
            question: Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø±
            
        Returns:
            Dict Ø¨Ø§ intent_type Ùˆ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨ÛŒØ´ØªØ±
        """
        q = (question or "").strip()
        q_lower = q.lower()

        # 1) Error / fault / alarm / code
        # Typical formats: CA1626, E15, CA-135, H-22, error 12, ERR12
        # NOTE: also treat H-codes (H-22, H22) as error-like
        error_code_pattern = r"\b(?:ca|e|err|error|h)\s*[-]?\s*\d+\b"
        extracted_code = None
        m = re.search(error_code_pattern, q_lower, re.IGNORECASE)
        if m:
            extracted_code = m.group().strip().upper().replace(" ", "")
            return {
                "intent": IntentType.ERROR_FIX,
                "confidence": "high",
                "extracted_code": extracted_code,
            }

        error_keywords = [
            "Ú©Ø¯ Ø®Ø·Ø§",
            "Ø®Ø·Ø§",
            "Ø§Ø±ÙˆØ±",
            "Ø¢Ù„Ø§Ø±Ù…",
            "alarm",
            "fault",
            "error",
        ]
        if any(k in q_lower for k in error_keywords):
            # If user says an error name but not a code, still treat as ERROR_FIX
            return {
                "intent": IntentType.ERROR_FIX,
                "confidence": "medium",
                "extracted_code": None,
            }

        # 2) Procedure / measurement / how-to (detailed steps)
        procedure_markers = [
            "Ú†Ø·ÙˆØ±",
            "Ú†Ú¯ÙˆÙ†Ù‡",
            "Ø±ÙˆØ´",
            "Ù…Ø±Ø§Ø­Ù„",
            "Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¨Ú¯ÛŒØ±",
            "Ø§Ù†Ø¯Ø§Ø²Ù‡ Ú¯ÛŒØ±ÛŒ",
            "ØªØ³Øª",
            "Ú†Ú© Ú©Ù†Ù…",
            "Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†Ù…",
            "Ù…ÙˆÙ„ØªÛŒ",
            "Ù…ÙˆÙ„ØªÛŒâ€ŒÙ…ØªØ±",
            "Ø§Ù‡Ù…",
            "Ù…Ù‚Ø§ÙˆÙ…Øª",
            "ÙˆÙ„ØªØ§Ú˜",
            "Ø¢Ù…Ù¾Ø±",
            "ÙˆÙ„Øª",
            "Ø§ØªØµØ§Ù„ Ú©ÙˆØªØ§Ù‡",
            "continuity",
            "ohm",
            "resistance",
            "voltage",
            "amp",
            "measure",
            "test",
            "check",
        ]
        if any(k in q_lower for k in procedure_markers):
            return {"intent": IntentType.PROCEDURE, "confidence": "high"}

        # 3) General / definition / overview
        general_markers = [
            "Ú†ÛŒØ³Øª",
            "Ú†ÛŒÙ‡",
            "ÛŒØ¹Ù†ÛŒ Ú†ÛŒ",
            "ØªØ¹Ø±ÛŒÙ",
            "Ù…ÙÙ‡ÙˆÙ…",
            "Ù…Ù†Ø¸ÙˆØ±",
            "what is",
            "define",
            "meaning",
            "overview",
            "ØªÙˆØ¶ÛŒØ­ Ú©Ù„ÛŒ",
        ]
        if any(k in q_lower for k in general_markers):
            return {"intent": IntentType.GENERAL, "confidence": "high"}

        # Short / ambiguous
        if len(q) < 6:
            return {
                "intent": IntentType.UNCLEAR,
                "confidence": "high",
                "reason": "Ø³ÙˆØ§Ù„ Ú©ÙˆØªØ§Ù‡/Ù†Ø§Ù…Ø´Ø®Øµ Ø§Ø³Øª",
            }

        # Default fallback: assume GENERAL (to avoid over-questioning),
        # but mark confidence low so we can ask only if needed.
        return {"intent": IntentType.GENERAL, "confidence": "low"}
    
    def generate_clarification_questions(self, question: str, intent_info: Dict) -> str:
        """
        ØªÙˆÙ„ÛŒØ¯ Ø³ÙˆØ§Ù„Ø§Øª Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ø¨Ø±Ø§ÛŒ Ø±ÙˆØ´Ù† Ø´Ø¯Ù† Ù…Ù†Ø¸ÙˆØ± Ú©Ø§Ø±Ø¨Ø±
        
        Args:
            question: Ø³ÙˆØ§Ù„ Ø§ØµÙ„ÛŒ Ú©Ø§Ø±Ø¨Ø±
            intent_info: Ø§Ø·Ù„Ø§Ø¹Ø§Øª intent
            
        Returns:
            Ù¾ÛŒØ§Ù… Ø­Ø§ÙˆÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±
        """
        # Ø§ÛŒÙ† Ù…ØªØ¯ ÙØ¹Ù„Ø§Ù‹ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø²Ú¯Ø§Ø±ÛŒ Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø´Ø¯Ù‡Ø›
        # Ù…Ù†Ø·Ù‚ Ø§ØµÙ„ÛŒ ØªÙÚ©ÛŒÚ© Ùˆ Ø³ÙˆØ§Ù„Ø§Øª Ø±ÙˆØ´Ù†â€ŒÚ©Ù†Ù†Ø¯Ù‡ Ø¯Ø§Ø®Ù„ Ù¾Ø±Ø§Ù…Ù¾Øª Ù…Ø¯Ù„ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯.
        return "Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ú©Ù…Ú©Øª Ú©Ù†Ù…ØŒ Ù„Ø·ÙØ§Ù‹ Ø³ÙˆØ§Ù„Øª Ø±Ø§ Ú©Ù…ÛŒ ÙˆØ§Ø¶Ø­â€ŒØªØ± Ùˆ Ø¨Ø§ Ø¬Ø²Ø¦ÛŒØ§Øª ÙÙ†ÛŒ Ø¨ÛŒØ´ØªØ± Ø¨Ù†ÙˆÛŒØ³."

    def _is_followup_question(self, question: str) -> bool:
        q = (question or "").strip().lower()
        followup_markers = [
            "Ø¹Ù„ØªØ´",
            "Ø¹Ù„Øª",
            "Ú†Ø±Ø§",
            "Ú†Ø·ÙˆØ±",
            "Ù¾Ø³",
            "Ø§ÛŒÙ†",
            "Ø§ÙˆÙ†",
            "Ø§ÛŒÙ†Ø§",
            "Ø§ÙˆÙ†Ø§",
            "Ù‡Ù…ÛŒÙ†",
            "Ø¨Ù‡Ø´",
            "Ø±Ø§Ø¬Ø¹ Ø¨Ù‡",
            "Ø±Ø§Ø¬Ø¹ Ø¨Ù‡Ø´",
            "Ø¯Ø±Ø¨Ø§Ø±Ù‡",
            "Ø¯Ø±Ø¨Ø§Ø±Ø´",
            "Ø¨ÛŒØ´ØªØ±",
            "Ú©Ø§Ù…Ù„",
            "Ú©Ø§Ù…Ù„â€ŒØªØ±",
            "Ø¯Ù‚ÛŒÙ‚",
            "Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±",
            "ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡",
            "ØªÙˆØ¶ÛŒØ­ Ø¨ÛŒØ´ØªØ±",
            "Ø¨Ú¯Ùˆ",
            "Ø¨Ú¯ÛŒ",
            "what about",
            "why",
            "how",
            "that",
            "this",
            "more about",
            "tell me more",
            "explain more",
        ]
        return len(q) < 30 or any(m in q for m in followup_markers)

    def _query_contains_persian(self, text: str) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© Ú©Ø§Ø±Ø§Ú©ØªØ± ÙØ§Ø±Ø³ÛŒ/Ø¹Ø±Ø¨ÛŒ Ø¯Ø± Ù…ØªÙ† (Ø¨Ø±Ø§ÛŒ Ø§Ø¹Ù…Ø§Ù„ ÙˆØ§Ú˜Ù‡â€ŒÙ†Ø§Ù…Ù‡)."""
        if not (text or "").strip():
            return False
        # Ù…Ø­Ø¯ÙˆØ¯Ù‡Ù” ÛŒÙˆÙ†ÛŒÚ©Ø¯: Ø¹Ø±Ø¨ÛŒØŒ ÙØ§Ø±Ø³ÛŒØŒ Ø§Ø¹Ø¯Ø§Ø¯ Ø¹Ø±Ø¨ÛŒ-ÙØ§Ø±Ø³ÛŒ
        for ch in text:
            if "\u0600" <= ch <= "\u06FF" or "\uFB50" <= ch <= "\uFDFF" or "\uFE70" <= ch <= "\uFEFF":
                return True
        return False

    def _expand_query_for_known_topics(self, query: str) -> str:
        """
        Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§ØªÛŒ Ú©Ù‡ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø¯Ø§Ø±Ù†Ø¯ØŒ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆØ§Ú˜Ù‡â€ŒÙ†Ø§Ù…Ù‡Ù” ÙØ§Ø±Ø³ÛŒâ€“Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒØŒ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡Ù” Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
        Ø¨Ù‡ Ú©ÙˆØ¦Ø±ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ ØªØ§ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¨Ù‡ Ú†Ø§Ù†Ú© Ø¯Ø±Ø³Øª Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ø±Ø³Ø¯.
        Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ú©Ø§Ù…Ù„Ø§Ù‹ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ù‡Ù… Ø§Ú¯Ø± Ø¯Ø± ÙˆØ§Ú˜Ù‡â€ŒÙ†Ø§Ù…Ù‡ ØªØ·Ø§Ø¨Ù‚ Ø¨Ø§Ø´Ø¯ Ú¯Ø³ØªØ±Ø´ Ø§Ø¹Ù…Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
        """
        if not (query or "").strip():
            return query
        q = query.strip()
        q_lower = q.lower()
        expansions = []

        # Ø§Ú¯Ø± Ø³ÙˆØ§Ù„ ÙØ§Ø±Ø³ÛŒ Ø¯Ø§Ø±Ø¯ØŒ Ù‡Ù…Ù‡Ù” Ù…Ø¯Ø®Ù„â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ú˜Ù‡â€ŒÙ†Ø§Ù…Ù‡ Ú©Ù‡ Ø¯Ø± Ø³ÙˆØ§Ù„ Ù‡Ø³ØªÙ†Ø¯ Ø±Ø§ Ø¨Ù‡ Ú©ÙˆØ¦Ø±ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
        if self._query_contains_persian(q):
            for persian_phrases, english_keywords in PERSIAN_ENGLISH_GLOSSARY:
                if any(phrase in q or phrase in q_lower for phrase in persian_phrases):
                    expansions.append(english_keywords)

        if not expansions:
            return query
        expanded = q + " " + " ".join(expansions)
        logger.info(f"Query expanded (glossary): '{q[:60]}...' -> added English keywords for {len(expansions)} term(s)")
        return expanded

    def _build_retrieval_query(self, question: str, conversation_history: Optional[List[Dict]]) -> str:
        """
        Improve retrieval for follow-up questions by using the last TECHNICAL question.
        """
        q = (question or "").strip()
        if not conversation_history:
            return q

        if not self._is_followup_question(q):
            return q

        # Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª follow-upØŒ Ø¨Ù‡ Ø¬Ø§ÛŒ Ø³ÙˆØ§Ù„ ÙØ¹Ù„ÛŒØŒ Ø§Ø² Ø³ÙˆØ§Ù„ ÙÙ†ÛŒ Ù‚Ø¨Ù„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        last_technical_q = None
        for msg in reversed(conversation_history):
            if (msg or {}).get("role") == "user":
                user_q = str((msg or {}).get("content", "")).strip()
                # Ø§Ú¯Ø± Ø³ÙˆØ§Ù„ ÙÙ†ÛŒ Ø¨ÙˆØ¯ (Ù†Ù‡ follow-up)ØŒ Ø§Ø² Ù‡Ù…ÙˆÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
                if user_q and not self._is_followup_question(user_q):
                    last_technical_q = user_q
                    logger.info(f"[Followup] Found last technical Q: '{last_technical_q}'")
                    break

        if not last_technical_q:
            logger.info(f"[Followup] No technical Q found, using current: '{q}'")
            return q

        # Ø¨Ø±Ø§ÛŒ retrievalØŒ ÙÙ‚Ø· Ø§Ø² Ø³ÙˆØ§Ù„ ÙÙ†ÛŒ Ù‚Ø¨Ù„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        # Ú†ÙˆÙ† Ù…Ø¯Ù„ Ø¨Ø¹Ø¯Ø§Ù‹ Ø§Ø² HISTORY Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù‡
        logger.info(f"[Followup] Using for retrieval: '{last_technical_q}'")
        return last_technical_q

    def _has_sufficient_context(self, relevant_docs: List[Dict]) -> bool:
        """
        Heuristic: we consider context sufficient if there is at least one retrieved chunk
        with a reasonable similarity (lower distance).
        """
        if not relevant_docs:
            return False
        try:
            best_distance = min(float(d.get("distance", 1.0)) for d in relevant_docs)
        except Exception:
            best_distance = 1.0
        return best_distance <= 0.55

    def _history_for_prompt(self, conversation_history: Optional[List[Dict]], max_items: int = 6) -> str:
        if not conversation_history:
            return "(Ù‡ÛŒÚ† Ù¾ÛŒØ§Ù… Ù‚Ø¨Ù„ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯)"
        items = conversation_history[-max_items:]
        lines = []
        for msg in items:
            role = (msg or {}).get("role", "")
            content = str((msg or {}).get("content", "")).strip()
            if len(content) > 600:
                content = content[:600] + "â€¦"
            if role == "user":
                lines.append(f"- user: {content}")
            elif role == "assistant":
                lines.append(f"- assistant: {content}")
            else:
                lines.append(f"- {role}: {content}")
        return "\n".join(lines)
    
    def answer_question(
        self,
        question: str,
        top_k: int = 20,
        use_reranking: bool = True,
        language: str = "persian",
        conversation_history: Optional[List[Dict]] = None
    ) -> Dict:
        """
        Answer a question using RAG approach Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª ØªØ¹Ø§Ù…Ù„ÛŒ Ø¨ÙˆØ¯Ù†
        
        Args:
            question: User's question
            top_k: Number of relevant chunks to retrieve
            use_reranking: Whether to use reranking for better results
            language: Response language (persian/english)
            conversation_history: ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù…Ú©Ø§Ù„Ù…Ù‡ Ù‚Ø¨Ù„ÛŒ
            
        Returns:
            Dictionary with answer, sources, and metadata
        """
        logger.info(f"Answering question: {question[:100]}...")
        
        # 1. ØªØ´Ø®ÛŒØµ Ù†ÙˆØ¹ Ú©Ù„ÛŒ Ø³ÙˆØ§Ù„ (ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ ØªÚ¯â€ŒÚ¯Ø°Ø§Ø±ÛŒ/Ù„Ø§Ú¯Ø› Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø±ÙØªØ§Ø± Ù…Ø¯Ù„)
        intent_info = self.detect_intent(question)
        logger.info(
            f"Detected intent: {intent_info.get('intent')} (confidence: {intent_info.get('confidence')})"
        )

        # 2. Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø³ØªÙ†Ø¯Ø§Øª: Ø§ÙˆÙ„ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Â«Ø¨Ø®Ø´ Ú©Ø§Ù…Ù„Â» Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ø¯ Ø®Ø·Ø§ (TOC)
        retrieval_query = self._build_retrieval_query(question, conversation_history)
        relevant_docs: List[Dict] = []
        section_used = None

        # 2a) Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø¯ Ø§Ø² Ø³ÙˆØ§Ù„Ø› Ø§ÙˆÙ„ Ù…Ø­Ø¯ÙˆØ¯Ù‡Ù” ØµÙØ­Ø§Øª ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² Ø§ÛŒÙ†Ø¯Ú©Ø³ (Ø¬Ø§ÛŒÛŒ Ú©Ù‡ Ú©Ø¯ Ø¯Ø± PDF Ø¢Ù…Ø¯Ù‡)ØŒ Ù†Ù‡ TOC
        # ØªÙˆØ¬Ù‡: Ø¯Ùˆ Ø§Ù„Ú¯Ùˆ Ù„Ø§Ø²Ù… Ø§Ø³Øª â€” (Û±) CA323, E-1, H-5 (Û²) DWK0KA, DX16KB (Ø­Ø±ÙˆÙ+Ø¹Ø¯Ø¯+Ø­Ø±ÙˆÙ)
        q_stripped = (question or "").strip()
        codes_in_query = re.findall(r"\b[A-Za-z]{1,3}-?\d{1,6}\b", q_stripped, re.IGNORECASE)
        codes_alpha_num = re.findall(r"\b[A-Za-z]{2,4}\d[A-Za-z]{2,5}\b", q_stripped, re.IGNORECASE)
        codes_in_query = list(dict.fromkeys(codes_in_query + codes_alpha_num))
        for code in codes_in_query:
            # Ø§ÙˆÙ„ Ø§Ø² Ø§ÛŒÙ†Ø¯Ú©Ø³: ØµÙØ­Ø§ØªÛŒ Ú©Ù‡ Ø§ÛŒÙ† Ú©Ø¯ ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ø¯Ø± Ø¢Ù†â€ŒÙ‡Ø§ Ø¸Ø§Ù‡Ø± Ø´Ø¯Ù‡ (Ø¬Ø¯ÙˆÙ„ Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ)
            page_range = self.vector_store.get_page_range_for_code(code, expand_adjacent=1)
            if page_range:
                start_page, end_page = page_range
                section_chunks = self.vector_store.get_chunks_by_page_range(
                    start_page, end_page, use_parent_context=True
                )
                if section_chunks:
                    relevant_docs = section_chunks
                    section_used = (code, start_page, end_page, "from index")
                    logger.info(f"Using full section for code '{code}' from index: pages {start_page}-{end_page}, {len(section_chunks)} pages")
                    break
            # Ø§Ú¯Ø± Ø¯Ø± Ø§ÛŒÙ†Ø¯Ú©Ø³ Ù†Ø¨ÙˆØ¯ØŒ Ø§Ø² TOC Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù† (Ù…Ù…Ú©Ù† Ø§Ø³Øª Ø´Ù…Ø§Ø±Ù‡Ù” ØµÙØ­Ù‡ Ø¯Ø± PDF Ù…ØªÙØ§ÙˆØª Ø¨Ø§Ø´Ø¯)
            info = get_section_page_range(code)
            if info:
                start_page, end_page, title = info
                # Ø¨Ø±Ø§ÛŒ Ú©Ø¯Ù‡Ø§ÛŒ Ø®Ø·Ø§ØŒ Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø±Ø§ Ú¯Ø³ØªØ±Ø´ Ø¨Ø¯Ù‡ ØªØ§ Ù‡Ù…Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§ (Ù…Ø«Ù„Ø§Ù‹ H-5 Ø¨Ø§ 3 Ø¬Ø¯ÙˆÙ„) Ø¨ÛŒØ§ÛŒØ¯
                # Ø§Ú¯Ø± TOC ÙÙ‚Ø· ÛŒÚ© ØµÙØ­Ù‡ Ø¯Ø§Ø¯ (end_page == start_page)ØŒ Ø­Ø¯Ø§Ù‚Ù„ 3 ØµÙØ­Ù‡ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
                if end_page == start_page:
                    expanded_end_page = start_page + 3
                else:
                    expanded_end_page = end_page + 2
                section_chunks = self.vector_store.get_chunks_by_page_range(
                    start_page, expanded_end_page, use_parent_context=True
                )
                if section_chunks:
                    relevant_docs = section_chunks
                    section_used = (code, start_page, expanded_end_page, title)
                    logger.info(f"Using full troubleshooting section for code '{code}' from TOC: pages {start_page}-{expanded_end_page} ({title}), {len(section_chunks)} chunks")
                    break

        # 2a1.5) ÙˆÙ‚ØªÛŒ Ú©Ø§Ø±Ø¨Ø± Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯ Â«Ù…Ø´Ú©Ù„ X Ø¯Ø§Ø±Ù…Â» / Â«X Ø®Ø±Ø§Ø¨ Ø§Ø³ØªÂ» Ø¨Ø¯ÙˆÙ† Ú©Ø¯ â€” Ù‡Ù…Ù‡Ù” Ú©Ø¯Ù‡Ø§ÛŒ Ø®Ø·Ø§ÛŒ Ø¢Ù† Ù‚Ø·Ø¹Ù‡ Ø±Ø§ Ø§Ø² Ø§ÛŒÙ†Ø¯Ú©Ø³ Ù„ÙˆØ¯ Ú©Ù†
        if not relevant_docs:
            text_to_check = (retrieval_query or "") + " " + (q_stripped or "")
            for comp_keywords, codes in COMPONENT_PROBLEM_TO_CODES:
                if not any(kw in text_to_check for kw in comp_keywords):
                    continue
                if not any(pm in text_to_check for pm in PROBLEM_MARKERS):
                    continue
                all_chunks: List[Dict] = []
                seen_key = set()
                for code in codes:
                    page_range = self.vector_store.get_page_range_for_code(code, expand_adjacent=1)
                    if page_range:
                        start_p, end_p = page_range
                        section_chunks = self.vector_store.get_chunks_by_page_range(
                            start_p, end_p, use_parent_context=True
                        )
                        for c in section_chunks:
                            pk = (c.get("page"), c.get("chunk_index", c.get("metadata", {}).get("chunk")), c.get("id"))
                            if pk not in seen_key:
                                seen_key.add(pk)
                                all_chunks.append(c)
                if all_chunks:
                    all_chunks.sort(key=lambda x: (x.get("page", 0), x.get("metadata", {}).get("chunk", 0)))
                    relevant_docs = all_chunks
                    section_used = ("component_problem", comp_keywords[0], codes)
                    logger.info(f"Using component-problem section for '{comp_keywords[0]}': codes {codes}, {len(relevant_docs)} chunks")
                break

        # 2a2) Ø§Ú¯Ø± Ø³ÙˆØ§Ù„ Ø¯Ø±Ø¨Ø§Ø±Ù‡Ù” ÛŒÚ© Ù¾Ø±ÙˆØ³ÛŒØ¬Ø± Ø´Ù†Ø§Ø®ØªÙ‡â€ŒØ´Ø¯Ù‡ Ø§Ø³Øª (Ù…Ø«Ù„ Bleeding air from each part)ØŒ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ø§ ØµÙØ­Ù‡ ÙˆØ§Ø±ÛŒØ² Ú©Ù†
        if not relevant_docs:
            q_lower = (question or "").strip().lower()
            rq_lower = (retrieval_query or "").strip().lower()
            for keywords, start_page, end_page in PROCEDURE_PAGE_MAP:
                if any(kw in q_lower or kw in rq_lower for kw in keywords):
                    procedure_chunks = self.vector_store.get_chunks_by_page_range(
                        start_page, end_page, use_parent_context=True
                    )
                    if procedure_chunks:
                        relevant_docs = procedure_chunks
                        section_used = (keywords[0], start_page, end_page, "procedure")
                        logger.info(f"Using procedure section for '{keywords[0]}': PDF pages {start_page}-{end_page}, {len(procedure_chunks)} chunks")
                    break

        # 2b) Ø§Ú¯Ø± Ø§Ø² Ø³ÙˆØ§Ù„ Ú©Ø¯ Ø¯Ø± TOC Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ Ùˆ Ù¾Ø±ÙˆØ³ÛŒØ¬Ø± Ù‡Ù… Ù†Ø¨ÙˆØ¯ØŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ù…Ø¹Ù…ÙˆÙ„ÛŒ (semantic + code expansion)
        if not relevant_docs:
            # Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª ØºÛŒØ±Ú©Ø¯ÛŒ (Ù…Ø«Ù„ Â«Ù…Ø±Ø§Ø­Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø¯ÛŒÙˆØ¯Â») Ú©ÙˆØ¦Ø±ÛŒ Ø±Ø§ Ø¨Ø§ ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ú¯Ø³ØªØ±Ø´ Ø¨Ø¯Ù‡
            retrieval_query = self._expand_query_for_known_topics(retrieval_query)
            if use_reranking:
                relevant_docs = self.vector_store.search_with_reranking(
                    query=retrieval_query,
                    top_k=top_k
                )
            else:
                relevant_docs = self.vector_store.search(
                    query=retrieval_query,
                    top_k=top_k
                )
            # 2c) Ø§Ø² Ø±ÙˆÛŒ ØµÙØ­Ù‡Ù” Ø§ÙˆÙ„ÛŒÙ† Ù†ØªØ§ÛŒØ¬ØŒ Ú©Ø¯ Ø®Ø·Ø§ Ø±Ø§ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ú©Ù† Ùˆ Ø§Ú¯Ø± Ø¯Ø± TOC Ø¨ÙˆØ¯ØŒ Ú©Ù„ Ø¨Ø®Ø´ Ø±Ø§ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†
            for doc in relevant_docs[:8]:
                page = doc.get("metadata", {}).get("page")
                if page is not None:
                    try:
                        p_int = int(page)
                        inferred_code = get_code_for_page(p_int)
                        if inferred_code:
                            info = get_section_page_range(inferred_code)
                            if info:
                                start_page, end_page, title = info
                                section_chunks = self.vector_store.get_chunks_by_page_range(
                                    start_page, end_page, use_parent_context=True
                                )
                                if section_chunks:
                                    relevant_docs = section_chunks
                                    section_used = (inferred_code, start_page, end_page, title)
                                    logger.info(f"Inferred code '{inferred_code}' from page {p_int}, using full section pages {start_page}-{end_page} ({title})")
                                    break
                    except (TypeError, ValueError):
                        pass

        logger.info(f"Retrieved {len(relevant_docs)} relevant documents" + (f" (full section for {section_used[0]})" if section_used else ""))
        
        # Log all retrieved documents for debugging
        if relevant_docs:
            for i, doc in enumerate(relevant_docs[:3]):  # Log first 3 docs
                doc_text = doc.get('text', '')[:300]
                doc_page = doc.get('metadata', {}).get('page', 'N/A')
                logger.info(f"Retrieved doc {i+1} (page {doc_page}): {doc_text}...")
        else:
            logger.warning("No documents retrieved! This is a problem!")

        # 3. ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ø¨Ø§ LLM (Ù…Ø¯Ù„ Ø®ÙˆØ¯Ø´ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù¾Ø±Ø§Ù…Ù¾ØªØŒ Ø³ÙˆØ§Ù„ Ø±Ø§ Ø¨Ù‡ ÛŒÚ©ÛŒ Ø§Ø² Ø­Ø§Ù„Øªâ€ŒÙ‡Ø§ÛŒ
        #    CASUAL_CHAT / TECH_ERROR / TECH_PROBLEM / TECH_INFO / ... Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯)
        result = self._generate_answer(
            question=question,
            relevant_docs=relevant_docs,
            language=language,
            intent_info=intent_info,
            conversation_history=conversation_history
        )
        
        # 4. ÙØ±Ù…Øª Ù…Ù†Ø§Ø¨Ø¹ Ùˆ Ø§ÙØ²ÙˆØ¯Ù† intent Ø¨Ø±Ø§ÛŒ UI
        result["sources"] = self._format_sources(relevant_docs)
        result["intent"] = intent_info.get("intent").value if isinstance(
            intent_info.get("intent"), IntentType
        ) else str(intent_info.get("intent"))
        
        return result
    
    def _generate_answer(
        self,
        question: str,
        relevant_docs: List[Dict],
        language: str,
        intent_info: Dict,
        conversation_history: Optional[List[Dict]] = None
    ) -> Dict:
        """
        Generate answer using LLM Ø¨Ø§ Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ† Intent Ùˆ History
        
        Args:
            question: User's question
            relevant_docs: List of relevant document chunks
            language: Response language
            intent_info: Ø§Ø·Ù„Ø§Ø¹Ø§Øª Intent
            conversation_history: ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù…Ú©Ø§Ù„Ù…Ù‡
            
        Returns:
            Dictionary with answer and metadata
        """
        # 1) Ø³Ø§Ø®Øª context Ø§Ø² Ù…Ø³ØªÙ†Ø¯Ø§Øª (Ø§Ú¯Ø± Ú†ÛŒØ²ÛŒ Ù¾ÛŒØ¯Ø§ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯)
        if not relevant_docs:
            logger.error("No relevant documents found! Cannot build context.")
            context = ""
        else:
            context = self._build_context(relevant_docs)
        
        # Log context for debugging
        logger.info(f"Built context length: {len(context)} characters")
        detected_sections = 0
        if context:
            # Check for multiple sections/phenomena in context.
            # IMPORTANT: Do NOT count every "(number)" in context (e.g. pin numbers (1),(2),(17),
            # page refs (38),(40)) as "sections" â€” that falsely forces "write 60 sections" and
            # confuses the LLM into saying "no info in docs". Only count explicit multi-part
            # headings like "Failure phenomenon (1)/(2)/(3)" or "Boom speed or power is low (1)/(2)/(3)".
            failure_phenomenon_patterns = [
                r"Failure\s+phenomenon\s*[â€¢Â·]\s*.*?\((\d+)\)",
                r"Failure\s+phenomenon\s*[â€¢Â·]\s*.*?\(1\)",
                r"Failure\s+phenomenon\s*[â€¢Â·]\s*.*?\(2\)",
                r"Failure\s+phenomenon\s*[â€¢Â·]\s*.*?\(3\)",
            ]
            section_count = 0
            for pattern in failure_phenomenon_patterns:
                matches = re.findall(pattern, context, re.IGNORECASE)
                if matches:
                    section_count = max(section_count, len(matches))
            # H-5 / H-22 style: "H-5 (1)", "H-5 (2)", "H-5 (3)" or similar
            h5_section_pattern = re.findall(r"H[- ]?5\s*\((\d+)\)|H[- ]?22\s*\((\d+)\)", context, re.IGNORECASE)
            if h5_section_pattern:
                flat = [int(n) for pair in h5_section_pattern for n in pair if n]
                if flat:
                    section_count = max(section_count, max(flat))
            # Boom speed or power is low (1), (2), (3)
            boom_patterns = re.findall(r"Boom\s+speed\s+or\s+power\s+is\s+low\s*\((\d+)\)", context, re.IGNORECASE)
            if boom_patterns:
                section_count = max(section_count, max([int(n) for n in boom_patterns if n.isdigit()]))
            # Do NOT use generic re.findall(r"\((\d+)\)", context) â€” it matches pin numbers and page refs.
            detected_sections = min(section_count, 20)  # cap at 20 to avoid any remaining false positives
            
            if section_count > 1:
                logger.info(f"âœ“ Found {section_count} sections/phenomena in context - LLM MUST include ALL of them!")
            else:
                logger.info(f"Found {section_count} section(s) in context")
            
            # Check if H-22 or similar codes are in context
            if "H-22" in context or "H22" in context.upper():
                logger.info("âœ“ H-22 found in context!")
            elif "H-5" in context or "H5" in context.upper():
                logger.info("âœ“ H-5 found in context!")
            
            logger.info(f"Context preview (first 1000 chars): {context[:1000]}...")
            logger.info(f"Context preview (last 500 chars): ...{context[-500:]}")
        else:
            logger.error("âŒ Context is EMPTY! This is why LLM says 'no info'")
        
        # 2) System prompt Ú†Ù†Ø¯Ø­Ø§Ù„ØªÙ‡ (ØªÙˆØ¶ÛŒØ­ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú†Ú¯ÙˆÙ†Ù‡ Ø¨ÛŒÙ† Ú†Øª Ø¹Ø§Ø¯ÛŒ Ùˆ Ø³ÙˆØ§Ù„ ÙÙ†ÛŒ Ø±ÙØªØ§Ø± Ú©Ù†Ø¯)
        system_prompt = self._get_system_prompt(language, intent_info)

        messages = [{"role": "system", "content": system_prompt}]

        # 3) HISTORY Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ (ÙÙ‚Ø· Ø¬Ù‡Øª Ø­Ø§ÙØ¸Ù‡ Ùˆ Ù¾ÛŒÙˆØ³ØªÚ¯ÛŒ Ù…Ú©Ø§Ù„Ù…Ù‡)
        history_text = self._history_for_prompt(conversation_history, max_items=6)

        # 4) user prompt Ø¨Ø§ Ø³Ù‡ Ø¨Ø®Ø´:
        #    - HISTORY
        #    - LAST_USER_MESSAGE
        #    - DOCUMENT_CONTEXT
        
        # Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª follow-upØŒ Ù…ÙˆØ¶ÙˆØ¹ Ù‚Ø¨Ù„ÛŒ Ø±Ø§ ØµØ±ÛŒØ­ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
        previous_topic_note = ""
        previous_answer_note = ""
        if conversation_history and self._is_followup_question(question):
            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¢Ø®Ø±ÛŒÙ† ØªØ¨Ø§Ø¯Ù„ (Ø³ÙˆØ§Ù„ Ùˆ Ø¬ÙˆØ§Ø¨)
            last_user_q = None
            last_assistant_a = None
            
            for i in range(len(conversation_history) - 1, -1, -1):
                msg = conversation_history[i]
                if msg.get("role") == "user" and not last_user_q:
                    user_q = str(msg.get("content", "")).strip()
                    if user_q and not self._is_followup_question(user_q):
                        last_user_q = user_q
                elif msg.get("role") == "assistant" and last_user_q and not last_assistant_a:
                    last_assistant_a = str(msg.get("content", "")).strip()[:500]  # ÙÙ‚Ø· 500 Ú©Ø§Ø±Ø§Ú©ØªØ± Ø§ÙˆÙ„
                    break
            
            if last_user_q:
                previous_topic_note = f"\nğŸ”” Ø³ÙˆØ§Ù„ Ù‚Ø¨Ù„ÛŒ Ú©Ø§Ø±Ø¨Ø±: {last_user_q}\n"
                if last_assistant_a:
                    previous_answer_note = f"ğŸ“ Ø®Ù„Ø§ØµÙ‡ Ù¾Ø§Ø³Ø® Ù‚Ø¨Ù„ÛŒ: {last_assistant_a}...\n\n"
                previous_topic_note += (
                    "âš ï¸ Ø³ÙˆØ§Ù„ Ø¬Ø¯ÛŒØ¯ Ú©Ø§Ø±Ø¨Ø± ('{question}') Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¨Ù‡ Ù‡Ù…ÛŒÙ† Ù…ÙˆØ¶ÙˆØ¹ Ø§Ø´Ø§Ø±Ù‡ Ø¯Ø§Ø±Ø¯. Ø¨Ø§ÛŒØ¯ Ù¾Ø§Ø³Ø® Ú©Ø§Ù…Ù„â€ŒØªØ± Ùˆ Ù…ÙØµÙ„â€ŒØªØ±ÛŒ Ø¯Ø±Ø¨Ø§Ø±Ù‡ Ù‡Ù…Ø§Ù† Ù…ÙˆØ¶ÙˆØ¹ Ø¨Ø¯Ù‡ÛŒ.\n"
                    "âš ï¸ Ø§Ú¯Ø± Ø³ÙˆØ§Ù„ Ù‚Ø¨Ù„ÛŒ Ø¯Ø±Ø¨Ø§Ø±Ù‡Ù” **ÛŒÚ© Ù‚Ø·Ø¹Ù‡Ù” Ø®Ø§Øµ** Ø¨ÙˆØ¯ (Ù…Ø«Ù„ Ø´ÛŒØ± Ø¨Ø§ÛŒâ€ŒÙ¾Ø³) Ùˆ Ø§Ù„Ø§Ù† Ú©Ø§Ø±Ø¨Ø± **Ø¹Ù„Ø§Ù…Øª** Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯ (Ù…Ø«Ù„Ø§Ù‹ Ú©Ø§Ù‡Ø´ Ù‚Ø¯Ø±ØªØŒ Ù„Ø±Ø²Ø´)ØŒ Ù¾Ø§Ø³Ø® Ø¨Ø§ÛŒØ¯ **ÙÙ‚Ø·** Ø§Ø² Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ Ù‡Ù…Ø§Ù† Ù‚Ø·Ø¹Ù‡ Ø¨Ø§Ø´Ø¯. Â«Ú©Ø§Ù‡Ø´ Ù‚Ø¯Ø±ØªÂ» Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø­Ø« = Ù‡Ù…Ø§Ù† Â«Output dropsÂ» ÛŒØ§ Â«Engine output lowersÂ» Ø¯Ø± Ú©Ø¯Ù‡Ø§ÛŒ Ø®Ø·Ø§ÛŒ Ø¢Ù† Ù‚Ø·Ø¹Ù‡. Ø§Ø² Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ù‚Ø·Ø¹Ø§Øª Ø¯ÛŒÚ¯Ø± (Ù…Ø«Ù„ H-5 Ø¨ÙˆÙ…ØŒ H-6 Ø¨Ø§Ø²Ùˆ) Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†.\n"
                )
        
        if language == "english":
            user_prompt = f"""
HISTORY:
{history_text}

{previous_topic_note}
{previous_answer_note}
LAST_USER_MESSAGE:
{question}

DOCUMENT_CONTEXT:
{context if context.strip() else "(empty)"}
"""
        else:
            # Build a more explicit context section
            if context and context.strip():
                # Add explicit warning if multiple sections detected
                section_warning = ""
                if detected_sections > 1:
                    section_warning = f"""
Ø³ÛŒØ³ØªÙ… ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ú©Ù‡ Ø¯Ø± DOCUMENT_CONTEXT Ø­Ø¯Ø§Ù‚Ù„ {detected_sections} Ø¨Ø®Ø´ / Ù¾Ø¯ÛŒØ¯Ù‡ Ù…Ø³ØªÙ‚Ù„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯.

Ø§Ù„Ø²Ø§Ù… Ù‚Ø·Ø¹ÛŒ:

Ø´Ù…Ø§ Ø¨Ø§ÛŒØ¯ Ù‡Ø± {detected_sections} Ø¨Ø®Ø´ Ø±Ø§ Ø¨Ù‡ Ø·ÙˆØ± Ú©Ø§Ù…Ù„ Ùˆ Ø¨Ø¯ÙˆÙ† Ø­Ø°Ù Ø­ØªÛŒ ÛŒÚ© Ù…ÙˆØ±Ø¯ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯.
Ù†ÙˆØ´ØªÙ† ÙÙ‚Ø· Ø¨Ø®Ø´ Ø§ÙˆÙ„ ÛŒØ§ Ø­Ø°Ù Ù‡Ø± ÛŒÚ© Ø§Ø² Ø¨Ø®Ø´â€ŒÙ‡Ø§ Ø¨Ù‡ Ù…Ø¹Ù†Ø§ÛŒ Ù¾Ø§Ø³Ø® Ù†Ø§Ù‚Øµ Ùˆ Ø§Ø´ØªØ¨Ø§Ù‡ Ø§Ø³Øª.

Ø§Ú¯Ø± DOCUMENT_CONTEXT Ø´Ø§Ù…Ù„ Ú†Ù†Ø¯ Ø¨Ø®Ø´ Ø´Ù…Ø§Ø±Ù‡â€ŒØ¯Ø§Ø± Ø§Ø³Øª:

Ù‡Ù…Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ø¢ÙˆØ±Ø¯Ù‡ Ø´ÙˆÙ†Ø¯

ØªØ±ØªÛŒØ¨ Ø¢Ù†â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ø­ÙØ¸ Ø´ÙˆØ¯

Ù‡ÛŒÚ† Ø¹Ù†ÙˆØ§Ù†ÛŒ Ø­Ø°Ù Ù†Ø´ÙˆØ¯

Ù‡ÛŒÚ† Ø¹Ù„Øª ÛŒØ§ Ù…Ù‚Ø¯Ø§Ø± Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ÛŒ Ø­Ø°Ù Ù†Ø´ÙˆØ¯

Ø³Ø§Ø®ØªØ§Ø± Ù‡Ø± Ø¨Ø®Ø´ Ø¨Ø§ÛŒØ¯ ÙˆØ§Ø¶Ø­ Ùˆ Ù‚Ø§Ø¨Ù„ ØªØ´Ø®ÛŒØµ Ø¨Ø§Ø´Ø¯ØŒ Ø§Ù…Ø§ Ø§Ø² Ù‚Ø§Ù„Ø¨â€ŒØ¨Ù†Ø¯ÛŒ Ø§ÙØ±Ø§Ø·ÛŒ Ùˆ ØªÚ©Ø±Ø§Ø±ÛŒ Ø®ÙˆØ¯Ø¯Ø§Ø±ÛŒ Ø´ÙˆØ¯.

Ù…Ø¯Ù„ ØµØ­ÛŒØ­ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø±Ø§ÛŒ {detected_sections} Ø¨Ø®Ø´

Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¨Ø®Ø´ Ø§Ø² Ø³Ø§Ø®ØªØ§Ø± Ø²ÛŒØ± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†:

Ø¨Ø®Ø´ 1
Ø¹Ù†ÙˆØ§Ù†:  [Ú©Ø¯]-1: [Ø¹Ù†ÙˆØ§Ù† Ø¨Ø®Ø´ 1]
Ø³Ù¾Ø³ ØªÙˆØ¶ÛŒØ­ Ú©Ø§Ù…Ù„ Ù‡Ù…Ø§Ù† Ø¨Ø®Ø´ Ø´Ø§Ù…Ù„:

ØªÙˆØ¶ÛŒØ­ ÙˆØ¶Ø¹ÛŒØª ÛŒØ§ Ù¾Ø¯ÛŒØ¯Ù‡

Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø·

Ø¹Ù„Ù„ Ùˆ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯

Ø³Ù¾Ø³ ÛŒÚ© Ø¬Ø¯Ø§Ú©Ù†Ù†Ø¯Ù‡ Ø³Ø§Ø¯Ù‡:

Ø¨Ø®Ø´ 2
Ø¹Ù†ÙˆØ§Ù†:  [Ú©Ø¯]-2: [Ø¹Ù†ÙˆØ§Ù† Ø¨Ø®Ø´ 2]
Ùˆ Ù‡Ù…Ø§Ù† Ø³Ø§Ø®ØªØ§Ø± Ú©Ø§Ù…Ù„ ØªÙˆØ¶ÛŒØ­

Ø¨Ø®Ø´ 3
Ø¹Ù†ÙˆØ§Ù†:  [Ú©Ø¯]-3: [Ø¹Ù†ÙˆØ§Ù† Ø¨Ø®Ø´ 3]
Ùˆ ØªÙˆØ¶ÛŒØ­ Ú©Ø§Ù…Ù„

Ùˆ Ø§ÛŒÙ† Ø±ÙˆÙ†Ø¯ Ø¨Ø§ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ù‡ {detected_sections} Ø¨Ø®Ø´ Ø§Ø¯Ø§Ù…Ù‡ Ù¾ÛŒØ¯Ø§ Ú©Ù†Ø¯.

Ù†Ú©ØªÙ‡ Ø¨Ø³ÛŒØ§Ø± Ù…Ù‡Ù…

Ø§Ú¯Ø± Ø­ØªÛŒ ÛŒÚ©ÛŒ Ø§Ø² {detected_sections} Ø¨Ø®Ø´ Ø­Ø°Ù Ø´ÙˆØ¯ ÛŒØ§ Ù†Ø§Ù‚Øµ Ù†ÙˆØ´ØªÙ‡ Ø´ÙˆØ¯ØŒ Ù¾Ø§Ø³Ø® Ø§Ø² Ù†Ø¸Ø± ÙÙ†ÛŒ Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³Øª.

Ø§Ù…Ø§ Ø¯Ø± Ø¹ÛŒÙ† Ø­Ø§Ù„:

Ø§Ø² ØªÚ©Ø±Ø§Ø± Ø¨ÛŒâ€ŒÙ…ÙˆØ±Ø¯ Ø¹Ù„Ø§Ø¦Ù… Ù‡Ø´Ø¯Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†

Ø§Ø² Ø¨ÙˆÙ„Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø§ÙØ±Ø§Ø·ÛŒ Ø®ÙˆØ¯Ø¯Ø§Ø±ÛŒ Ú©Ù†

Ø¸Ø§Ù‡Ø± Ù¾Ø§Ø³Ø® Ø¨Ø§ÛŒØ¯ ØªÙ…ÛŒØ²ØŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ùˆ Ù‚Ø§Ø¨Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† Ø¨Ø§Ø´Ø¯
"""
                
                context_section = f"""
DOCUMENT_CONTEXT (Ù…ØªÙ† Ú©Ø§Ù…Ù„ Ø§Ø² Ù…Ø³ØªÙ†Ø¯Ø§Øª):
{context}

âš ï¸ ØªÙˆØ¬Ù‡: Ù…ØªÙ† Ø¨Ø§Ù„Ø§ Ø§Ø² Ù…Ø³ØªÙ†Ø¯Ø§Øª ÙÙ†ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø­ØªÙ…Ø§Ù‹ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†!
âœ… Ú†ÙˆÙ† DOCUMENT_CONTEXT Ù…Ø­ØªÙˆØ§ Ø¯Ø§Ø±Ø¯ØŒ Ù‡Ø±Ú¯Ø² Ù†Ú¯Ùˆ Â«Ø¯Ø± Ù…Ø³ØªÙ†Ø¯Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³ØªÂ» â€” Ø§Ø² Ù‡Ù…ÛŒÙ† Ù…ØªÙ† Ù¾Ø§Ø³Ø® Ø¨Ø¯Ù‡.
{section_warning}
"""
            else:
                context_section = "\nDOCUMENT_CONTEXT: (Ø®Ø§Ù„ÛŒ - Ù‡ÛŒÚ† Ù…Ø³ØªÙ†Ø¯ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯)\n"
            
            # Add explicit instruction based on detected sections
            multi_section_instruction = ""
            if detected_sections > 1:
                multi_section_instruction = f"""
 Ø¯Ø³ØªÙˆØ± Ø§Ø¬Ø¨Ø§Ø±ÛŒ Ùˆ Ø­ÛŒØ§ØªÛŒ: Ø³ÛŒØ³ØªÙ… ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ú©Ù‡ Ø¯Ø± DOCUMENT_CONTEXT Ø­Ø¯Ø§Ù‚Ù„ {detected_sections} Ø¨Ø®Ø´ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯!
 Ø´Ù…Ø§ **Ø­ØªÙ…Ø§Ù‹ Ø¨Ø§ÛŒØ¯ Ù‡Ù…Ù‡ {detected_sections} Ø¨Ø®Ø´ Ø±Ø§ Ú©Ø§Ù…Ù„ Ø¨Ù†ÙˆÛŒØ³ÛŒ**!
 Ù‚Ø¨Ù„ Ø§Ø² Ù†ÙˆØ´ØªÙ† Ù¾Ø§Ø³Ø®ØŒ DOCUMENT_CONTEXT Ø±Ø§ Ú©Ø§Ù…Ù„ Ø¨Ø®ÙˆØ§Ù† Ùˆ Ù‡Ù…Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§ Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ú©Ù†.
 Ø³Ù¾Ø³ Ù‡Ø± Ø¨Ø®Ø´ Ø±Ø§ Ø¨Ø§ Ø¹Ù†ÙˆØ§Ù† Ù…Ø´Ø®Øµ (Ù…Ø«Ù„Ø§Ù‹ " H-5-1: ...", " H-5-2: ...", " H-5-3: ...") Ø¬Ø¯Ø§ Ú©Ù† Ùˆ Ú©Ø§Ù…Ù„ Ø¨Ù†ÙˆÛŒØ³.
 Ù‡ÛŒÚ†â€ŒÙˆÙ‚Øª ÙÙ‚Ø· Ø¨Ø®Ø´ Ø§ÙˆÙ„ Ø±Ø§ Ù†Ù†ÙˆÛŒØ³ Ùˆ Ø¨Ù‚ÛŒÙ‡ Ø±Ø§ Ø­Ø°Ù Ù†Ú©Ù†!

**Ø³Ø§Ø®ØªØ§Ø± Ø§Ø¬Ø¨Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø®:**
Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¨Ø®Ø´ Ø¨Ø§ÛŒØ¯ Ø§ÛŒÙ† Ø³Ø§Ø®ØªØ§Ø± Ø±Ø§ Ø±Ø¹Ø§ÛŒØª Ú©Ù†ÛŒ:
- Ø¹Ù†ÙˆØ§Ù†: ` [Ú©Ø¯]-[Ø´Ù…Ø§Ø±Ù‡ Ø¨Ø®Ø´]: [Ø¹Ù†ÙˆØ§Ù†]`
- Ù¾Ø¯ÛŒØ¯Ù‡ Ø®Ø±Ø§Ø¨ÛŒ
- Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø·
- Ø¹Ù„Ù„ Ùˆ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
- Ø®Ø· Ø¬Ø¯Ø§Ú©Ù†Ù†Ø¯Ù‡ `---` Ø¨ÛŒÙ† Ø¨Ø®Ø´â€ŒÙ‡Ø§

**Ù…Ø«Ø§Ù„:** Ø§Ú¯Ø± H-5 Ø§Ø³Øª Ùˆ 3 Ø¨Ø®Ø´ Ø¯Ø§Ø±Ø¯:
- âœ… Ø¯Ø±Ø³Øª: Ù‡Ù…Ù‡ 3 Ø¨Ø®Ø´ Ø±Ø§ Ø¨Ø§ Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ù„Ø§ Ø¨Ù†ÙˆÛŒØ³ (H-5-1ØŒ H-5-2ØŒ H-5-3)
- âŒ ØºÙ„Ø·: ÙÙ‚Ø· Ø¨Ø®Ø´ Ø§ÙˆÙ„ Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³

"""
            
            user_prompt = f"""
HISTORY:
{history_text}

{previous_topic_note}
{previous_answer_note}
LAST_USER_MESSAGE:
{question}

{context_section}

{multi_section_instruction}
 Ø¯Ø³ØªÙˆØ±Ø§Øª Ø¨Ø³ÛŒØ§Ø± Ù…Ù‡Ù… Ùˆ Ø§Ø¬Ø¨Ø§Ø±ÛŒ (Ø­ØªÙ…Ø§Ù‹ Ø±Ø¹Ø§ÛŒØª Ú©Ù†):
0. **Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„ Â«Ú†ÛŒÙ‡/Ú†ÛŒØ³Øª/ØªØ¹Ø±ÛŒÙÂ» ÙˆÙ‚ØªÛŒ DOCUMENT_CONTEXT Ù…Ø´Ø®ØµØ§Øª ÙÙ†ÛŒ Ø¯Ø§Ø±Ø¯:** Ø§ÙˆÙ„ ÛŒÚ© ØªÙˆØ¶ÛŒØ­ Ú©ÙˆØªØ§Ù‡ Ø¨Ø¯Ù‡ Ú©Ù‡ Ù‚Ø·Ø¹Ù‡ Ú†ÛŒØ³Øª Ùˆ Ø¯Ø± Ø¯Ø³ØªÚ¯Ø§Ù‡ Ú†Ù‡ Ù†Ù‚Ø´ÛŒ Ø¯Ø§Ø±Ø¯ (Ù…Ø«Ù„Ø§Ù‹ Ù…ÙˆØªÙˆØ± Ú†Ø±Ø®Ø´ÛŒ = Swing motor Ø¨Ø±Ø§ÛŒ Ú†Ø±Ø®Ø´ Ù‚Ø³Ù…Øª ÙÙˆÙ‚Ø§Ù†ÛŒ)ØŒ Ø¨Ø¹Ø¯ **Ù‡Ù…Ù‡** Ù…Ø´Ø®ØµØ§Øª Ùˆ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ø±Ø§ Ø§Ø² Ù…Ø³ØªÙ†Ø¯Ø§Øª Ú©Ø§Ù…Ù„ Ø¨ÛŒØ§ÙˆØ± (Ù†Ø³Ø¨Øª Ú©Ø§Ù‡Ø´ØŒ Ø¯Ù†Ø¯Ø§Ù†Ù‡â€ŒÙ‡Ø§ØŒ Ú¯Ø±ÛŒØ³ØŒ ÙØ§ØµÙ„Ù‡ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ØŒ Ø­Ø¯ ØªØ¹Ù…ÛŒØ±/ØªØ¹ÙˆÛŒØ¶ØŒ Ù†Ú©Ø§Øª). Ù‡ÛŒÚ†â€ŒÙˆÙ‚Øª ÙÙ‚Ø· ØªÙˆØ¶ÛŒØ­ Ú©Ù„ÛŒ Ù†Ø¯Ù‡ Ùˆ Ù…Ø´Ø®ØµØ§Øª Ù…Ø³ØªÙ†Ø¯ Ø±Ø§ Ø­Ø°Ù Ù†Ú©Ù†.
1. **Ù¾Ø§Ø³Ø® ÙÙ‚Ø· Ø§Ø² DOCUMENT_CONTEXT Ùˆ Ú©Ø§Ù…Ù„:** Ù¾Ø§Ø³Ø® ØªÙˆ Ø¨Ø§ÛŒØ¯ **ÙÙ‚Ø·** Ø¨Ø± Ø§Ø³Ø§Ø³ DOCUMENT_CONTEXT Ø¨Ø§Ø´Ø¯ Ùˆ **Ù‡ÛŒÚ† Ú†ÛŒØ²ÛŒ Ø®Ù„Ø§ØµÙ‡ ÛŒØ§ Ø¬Ø§ Ø§Ù†Ø¯Ø§Ø®ØªÙ‡ Ù†Ø´ÙˆØ¯.** (Û±) Ù‡Ø± Ø¨Ø®Ø´ Ø§ØµÙ„ÛŒ (Ù…Ø«Ù„Ø§Ù‹ 1. 2. 3. 4. 5. 6.) Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ â€” Ø­Ø°Ù Ø­ØªÛŒ ÛŒÚ© Ø¨Ø®Ø´ Ù…Ù…Ù†ÙˆØ¹. (Û²) Ø¬Ø¯ÙˆÙ„â€ŒÙ‡Ø§ Ùˆ Ø´Ø±Ø§ÛŒØ· Ø§ÙˆÙ„ÛŒÙ‡ (Measuring deviceØŒ Hydraulic oil temperatureØŒ Ø¬Ø¯ÙˆÙ„ Inspection port/Measurement ports Ùˆ ØºÛŒØ±Ù‡) Ø±Ø§ Ú©Ø§Ù…Ù„ Ø¨ÛŒØ§ÙˆØ±. (Û³) Ù‡Ø± Ø´Ù…Ø§Ø±Ù‡ Ù‚Ø·Ø¹Ù‡ (Part number Ùˆ Flange  / Plug ) Ø±Ø§ Ø¯Ù‚ÛŒÙ‚ Ø¯Ø± Ø¬Ø§ÛŒ Ø®ÙˆØ¯ Ø¨Ù†ÙˆÛŒØ³. (Û´) ØªØ±ØªÛŒØ¨ Ù…Ø±Ø§Ø­Ù„ Ø±Ø§ Ø¹ÛŒÙ† Ù…Ø³ØªÙ†Ø¯ Ø­ÙØ¸ Ú©Ù†. Ø®Ù„Ø§ØµÙ‡ Ù†Ú©Ù†.

1. Ø§Ú¯Ø± DOCUMENT_CONTEXT Ù…Ø­ØªÙˆØ§ Ø¯Ø§Ø±Ø¯ (Ø­ØªÛŒ ÛŒÚ© Ø®Ø·)ØŒ Ø­ØªÙ…Ø§Ù‹ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù† Ùˆ **Ù‡Ù…Ù‡** Ø¬Ø²Ø¦ÛŒØ§Øª Ø±Ø§ Ú©Ø§Ù…Ù„ Ø¨Ù†ÙˆÛŒØ³.

2. **Ø¨Ø±Ø§ÛŒ Ú©Ø¯ Ø®Ø·Ø§ Ùˆ Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ â€” Ù„Ø­Ù† ØªØ¹Ø§Ù…Ù„ÛŒ Ùˆ Ù‚Ø§Ø¨Ù„â€ŒÙÙ‡Ù…:** Ø§Ú¯Ø± Ø³ÙˆØ§Ù„ Ø¯Ø±Ø¨Ø§Ø±Ù‡Ù” Ú©Ø¯ Ø®Ø·Ø§ (Ù…Ø«Ù„ CA135ØŒ CA141 Ùˆ ØºÛŒØ±Ù‡) ÛŒØ§ Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ Ø§Ø³ØªØŒ Ù¾Ø§Ø³Ø® Ø±Ø§ Ø·ÙˆØ±ÛŒ Ø¨Ù†ÙˆÛŒØ³ Ú©Ù‡ Ú©Ø§Ø±Ø¨Ø± Ø§Ø­Ø³Ø§Ø³ Ú©Ù†Ø¯ Ø¨Ø§ ÛŒÚ© Ù†ÙØ± Ù‚Ø¯Ù…â€ŒØ¨Ù‡â€ŒÙ‚Ø¯Ù… Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ù…Ù‚Ø§Ø¯ÛŒØ± Ø±Ø§ Ø¨Ù‡ ØµÙˆØ±Øª Ø¬Ù…Ù„Ù‡Ù” Ø±Ø§Ù‡Ù†Ù…Ø§ Ø¨Ù†ÙˆÛŒØ³ (Ù…Ø«Ù„Ø§Ù‹ Â«Ù…Ù‚Ø§ÙˆÙ…Øª Ø¨ÛŒÙ† ÙÙ„Ø§Ù† Ùˆ ÙÙ„Ø§Ù† Ø¨Ø§ÛŒØ¯ Ø­Ø¯Ø§Ú©Ø«Ø± Û± Ø§Ù‡Ù… Ø¨Ø§Ø´Ù‡Â» ÛŒØ§ Â«ÙˆÙ„ØªØ§Ú˜ Ø§ÛŒÙ† Ø¯Ùˆ Ù†Ù‚Ø·Ù‡ Ø¨Ø§ÛŒØ¯ Ø¨ÛŒÙ† Û´Ù«Û·Ûµ ØªØ§ ÛµÙ«Û²Ûµ ÙˆÙ„Øª Ø¨Ø§Ø´Ù‡Â»)Ø› Ù‚Ø¨Ù„ Ø§Ø² Ù‡Ø± Ø¯Ø³ØªÙ‡ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ ØªÙˆØ¶ÛŒØ­ Ú©ÙˆØªØ§Ù‡ Ø¨Ø¯Ù‡ Ú©Ù‡ Ø§Ù„Ø§Ù† Ú†ÛŒ Ø±Ùˆ Ú†Ú© Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…Ø› Ø§Ø² Ø¹Ø¨Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø«Ù„ Â«Ø§ÙˆÙ„ Ø§ÛŒÙ† Ø±Ùˆ Ú†Ú© Ú©Ù†Â»ØŒ Â«Ø¨Ø¹Ø¯ Ø§ÛŒÙ† Ù…Ù‚Ø¯Ø§Ø± Ø±Ùˆ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¨Ú¯ÛŒØ±Â» Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†. Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙÙ†ÛŒ Ùˆ Ø§Ø¹Ø¯Ø§Ø¯ Ø±Ø§ Ú©Ø§Ù…Ù„ Ùˆ Ø¯Ù‚ÛŒÙ‚ Ø­ÙØ¸ Ú©Ù†ØŒ ÙÙ‚Ø· **Ø´ÛŒÙˆÙ‡Ù” Ø¨ÛŒØ§Ù†** Ø±Ø§ Ø¯ÙˆØ³ØªØ§Ù†Ù‡ Ùˆ Ø±Ø§Ù‡Ù†Ù…Ø§Ú¯ÙˆÙ†Ù‡ Ú©Ù†.

2b. **ÙˆÙ‚ØªÛŒ Ú©Ø§Ø±Ø¨Ø± Ú¯ÙØªÙ‡ Â«Ù…Ø´Ú©Ù„ X Ø¯Ø§Ø±Ù…Â» ÛŒØ§ Â«X Ø®Ø±Ø§Ø¨ Ø§Ø³ØªÂ» (Ø¨Ø¯ÙˆÙ† Ø°Ú©Ø± Ú©Ø¯):** Ø§Ú¯Ø± Ø¯Ø± DOCUMENT_CONTEXT Ú†Ù†Ø¯ **Failure code [CAxxxx]** (ÛŒØ§ Ú©Ø¯Ù‡Ø§ÛŒ Ù…Ø´Ø§Ø¨Ù‡) Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ù‡Ù…Ø§Ù† Ù‚Ø·Ø¹Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯: (Û±) Ø§ÙˆÙ„ **Ù‡Ù…Ù‡** Ø¢Ù† Ú©Ø¯Ù‡Ø§ Ø±Ø§ Ø¨Ø§ Ø´Ù…Ø§Ø±Ù‡ Ùˆ Ø¹Ù†ÙˆØ§Ù† Ú©ÙˆØªØ§Ù‡ ÙÙ‡Ø±Ø³Øª Ú©Ù†ØŒ (Û²) **Ø³ÙˆØ§Ù„ Ø¨Ù¾Ø±Ø³**: Â«Ø¢ÛŒØ§ Ø±ÙˆÛŒ Ù…Ø§Ù†ÛŒØªÙˆØ± Ú©Ø¯ Ø®Ø·Ø§ Ù…ÛŒâ€ŒØ¨ÛŒÙ†ÛŒØ¯ØŸ Ø§Ú¯Ø± Ø¨Ù„Ù‡ØŒ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ú†Ù‡ Ú©Ø¯ÛŒØŸ Ø§Ú¯Ø± Ù†Ù‡ØŒ Ú†Ù‡ Ø§ØªÙØ§Ù‚ÛŒ Ù…ÛŒâ€ŒØ§ÙØªØ¯ØŸ (Ù…Ø«Ù„Ø§Ù‹ Ù‚Ø¯Ø±Øª Ú©Ù…ØŒ Ù„Ø±Ø²Ø´)Â»ØŒ (Û³) Ø¨Ø¹Ø¯ Ø§Ø² Ø¬ÙˆØ§Ø¨ Ú©Ø§Ø±Ø¨Ø±ØŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù‡Ù…Ø§Ù† Ú©Ø¯ ÛŒØ§ Ø¹Ù„Ø§Ù…Øª **Ù‚Ø¯Ù…â€ŒØ¨Ù‡â€ŒÙ‚Ø¯Ù…** Ø§Ø² Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ Ú©Ù†. **Ù‡Ø±Ú¯Ø²** ÙÙ‚Ø· ÛŒÚ© ØªÙˆØµÛŒÙ‡Ù” Ú©Ù„ÛŒ (Ù…Ø«Ù„ ØªØ¹ÙˆÛŒØ¶ Ø±ÙˆØºÙ† ÛŒØ§ Ø´Ø³ØªØ´ÙˆÛŒ Ù…Ø¯Ø§Ø±) Ù†Ø¯Ù‡ ÙˆÙ‚ØªÛŒ Ø¯Ø± Ù…Ø³ØªÙ†Ø¯ Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ Ø¯Ù‚ÛŒÙ‚ Ùˆ Ú©Ø¯Ù‡Ø§ÛŒ Ù…Ø´Ø®Øµ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯.

3. **Ù‚Ø§Ù†ÙˆÙ† Ø·Ù„Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ú†Ù†Ø¯Ø¨Ø®Ø´ÛŒ - Ø§ÛŒÙ† Ù‚Ø§Ù†ÙˆÙ† Ø±Ø§ Ø­ØªÙ…Ø§Ù‹ Ø±Ø¹Ø§ÛŒØª Ú©Ù†:**
   
   **Ø§Ú¯Ø± Ø¯Ø± DOCUMENT_CONTEXT Ú†Ù†Ø¯ÛŒÙ† Ø¨Ø®Ø´/Ø¬Ø¯ÙˆÙ„/Ù¾Ø¯ÛŒØ¯Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ (Ù…Ø«Ù„Ø§Ù‹ "Failure phenomenon (1)", "Failure phenomenon (2)", "Failure phenomenon (3)" ÛŒØ§ "Boom speed or power is low (1)", "Boom speed or power is low (2)", "Boom speed or power is low (3)" Ùˆ ØºÛŒØ±Ù‡)ØŒ Ø¨Ø§ÛŒØ¯ **Ù‡Ù…Ù‡** Ø¨Ø®Ø´â€ŒÙ‡Ø§ Ø±Ø§ Ú©Ø§Ù…Ù„ Ø¨Ù†ÙˆÛŒØ³ÛŒ!**
   
   **Ø³Ø§Ø®ØªØ§Ø± Ø§Ø¬Ø¨Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¨Ø®Ø´:**
   ```
   [Ú©Ø¯]-[Ø´Ù…Ø§Ø±Ù‡]: [Ø¹Ù†ÙˆØ§Ù† Ø¨Ø®Ø´]
   
   Ù¾Ø¯ÛŒØ¯Ù‡ Ø®Ø±Ø§Ø¨ÛŒ
   [ØªÙˆØ¶ÛŒØ­ Ú©Ø§Ù…Ù„]
   
    Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±ØªØ¨Ø·
   [Ù‡Ù…Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª - Ú©Ø§Ù…Ù„]
    Ø¹Ù„Ù„ Ùˆ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
   [Ù‡Ù…Ù‡ Ø¹Ù„Ù„ - Ú©Ø§Ù…Ù„]
   
   ---
   ```
   
   **Ù…Ø«Ø§Ù„ Ú©Ø§Ù…Ù„ Ø¨Ø±Ø§ÛŒ H-5 (Ú©Ù‡ 3 Ø¨Ø®Ø´ Ø¯Ø§Ø±Ø¯):**
   - âœ… Ø¯Ø±Ø³Øª: Ù‡Ù…Ù‡ 3 Ø¨Ø®Ø´ Ø±Ø§ Ø¨Ø§ Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ù„Ø§ Ø¨Ù†ÙˆÛŒØ³:
     - ` H-5-1: Ø³Ø±Ø¹Øª ÛŒØ§ Ù‚Ø¯Ø±Øª Ø¨ÙˆÙ… Ú©Ù… Ø§Ø³Øª (Ø­Ø§Ù„Øª Ù†Ø±Ù…Ø§Ù„)`
     - ` H-5-2: Ø³Ø±Ø¹Øª ÛŒØ§ Ù‚Ø¯Ø±Øª Ø¨Ø§Ù„Ø§ Ø±ÙØªÙ† Ø¨ÙˆÙ… Ø¯Ø± Ø­Ø§Ù„Øª Heavy lift Ú©Ù… Ø§Ø³Øª`
     - ` H-5-3: Ø³Ø±Ø¹Øª ÛŒØ§ Ù‚Ø¯Ø±Øª Ù¾Ø§ÛŒÛŒÙ† Ø¢Ù…Ø¯Ù† Ø¨ÙˆÙ… Ø¯Ø± Ø­Ø§Ù„Øª Machine push-up Ú©Ù… Ø§Ø³Øª`
   - âŒ ØºÙ„Ø·: ÙÙ‚Ø· Ø¨Ø®Ø´ Ø§ÙˆÙ„ Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ Ùˆ Ø¨Ù‚ÛŒÙ‡ Ø±Ø§ Ø­Ø°Ù Ú©Ù†

4. Ø§Ú¯Ø± Ú†Ù†Ø¯ÛŒÙ† Ø¹Ù„Øª (Cause) Ø¯Ø± DOCUMENT_CONTEXT ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ø¨Ø§ÛŒØ¯ **Ù‡Ù…Ù‡** Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒ - Ù‡ÛŒÚ†â€ŒÙˆÙ‚Øª ÙÙ‚Ø· Ú†Ù†Ø¯ ØªØ§ Ø±Ø§ Ù†Ù†ÙˆÛŒØ³!

5. Ø§Ú¯Ø± Ú†Ù†Ø¯ÛŒÙ† Ø¬Ø¯ÙˆÙ„ (Table) ÛŒØ§ Ú†Ù†Ø¯ÛŒÙ† "Presumed cause" ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ø¨Ø§ÛŒØ¯ **Ù‡Ù…Ù‡** Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒ!

6. **Ù‡Ø±Ú¯Ø² ØªØ­Øª Ù‡ÛŒÚ† Ø´Ø±Ø§ÛŒØ·ÛŒ Ø§Ú¯Ø± DOCUMENT_CONTEXT Ø­ØªÛŒ ÛŒÚ© Ø®Ø· Ù…Ø­ØªÙˆØ§ Ø¯Ø§Ø±Ø¯ Ù†Ú¯Ùˆ "Ø¯Ø± Ù…Ø³ØªÙ†Ø¯Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª" ÛŒØ§ "Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ Ø¯Ø± Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø§Ø±Ø§Ø¦Ù‡ Ù†Ø´Ø¯Ù‡".** Ø§Ø² Ù‡Ù…Ø§Ù† Ù…Ø­ØªÙˆØ§ (Ø­ØªÛŒ ÙÙ‡Ø±Ø³ØªØŒ Ù…Ø±Ø¬Ø¹ ØµÙØ­Ù‡ØŒ ÛŒØ§ Ú©Ø¯ Ø®Ø·Ø§) Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù† Ùˆ Ù¾Ø§Ø³Ø® Ø¨Ø¯Ù‡.

7. Ù‡ÛŒÚ†â€ŒÙˆÙ‚Øª Ø¬ÙˆØ§Ø¨ Ø±Ø§ Ú©ÙˆØªØ§Ù‡ Ù†Ú©Ù† ÛŒØ§ Ø®Ù„Ø§ØµÙ‡ Ù†Ú©Ù†. Ø¨Ø±Ø§ÛŒ **Ù¾Ø±ÙˆØ³ÛŒØ¬Ø±** Ú©Ø§Ø±Ø¨Ø± Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡Ø¯ **Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ø¨Ù‡ Ø§Ù†Ø¯Ø§Ø²Ù‡Ù” Ù…Ø³ØªÙ†Ø¯** Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨Ø¨ÛŒÙ†Ø¯: (Û±) Note Ø§Ø¨ØªØ¯Ø§ÛŒÛŒ Ø±Ø§ Ø¯Ø± Ø§ÙˆÙ„ Ø¨ÛŒØ§ÙˆØ± (Û²) Ù‡Ù…Ø§Ù† Ø´Ù…Ø§Ø±Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø±Ø§ Ø­ÙØ¸ Ú©Ù†: 1. 2. 3. 4. 5. 6. Ùˆ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ù…Ø±Ø­Ù„Ù‡ 1) 2) 3) Ùˆ i) ii) (Û³) Ù‡Ø± Ø¬Ù…Ù„Ù‡Ù” Â«aÂ» (Ø§Ø­ØªÛŒØ§Ø·/Ù†Ú©ØªÙ‡) Ø±Ø§ Ø¬Ø¯Ø§ Ø¨Ù†ÙˆÛŒØ³ (Û´) Ù‡Ø± Ú¯Ø´ØªØ§ÙˆØ± Ø±Ø§ Ø¨Ø§ Nm Ùˆ kgm Ùˆ Ù‡Ø± ÙˆØ²Ù† (Ù…Ø«Ù„Ø§Ù‹ 130 kg) Ø¬Ø¯Ø§ Ø¨Ù†ÙˆÛŒØ³ (Ûµ) Ù…Ø±Ø­Ù„Ù‡Ù” Û± (Ù…Ø«Ù„Ø§Ù‹ Bleeding air from work equipment pump and fan pump) Ø±Ø§ Ø¨Ø§ Ù‡Ù…Ù‡Ù” Ø²ÛŒØ±Ù…Ø±Ø§Ø­Ù„ Ùˆ Ù†Ú©Ø§Øª Ùˆ Ú¯Ø´ØªØ§ÙˆØ± Bleeder Ú©Ø§Ù…Ù„ Ø¨ÛŒØ§ÙˆØ±Ø› Ù…Ø±Ø­Ù„Ù‡Ù” Û² (Starting engine) Ø±Ø§ Ø­ØªÛŒ Ø§Ú¯Ø± ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ø§Ø³Øª Ø­Ø°Ù Ù†Ú©Ù†. Ø§Ø² Ù‚Ø§Ù„Ø¨ Â«Ù¾Ø¯ÛŒØ¯Ù‡ Ø®Ø±Ø§Ø¨ÛŒ / Ø¹Ù„Ù„ Ùˆ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯Â» Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†.

8. Ø§Ú¯Ø± DOCUMENT_CONTEXT Ø®Ø§Ù„ÛŒ Ø§Ø³Øª (ÛŒØ¹Ù†ÛŒ ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ù‡ÛŒÚ† Ù…ØªÙ†ÛŒ Ù†Ø¯Ø§Ø±Ø¯)ØŒ ÙÙ‚Ø· Ø¯Ø± Ø§ÛŒÙ† ØµÙˆØ±Øª Ø¨Ú¯Ùˆ Ú©Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.

9. **Ù‚Ø¨Ù„ Ø§Ø² Ù†ÙˆØ´ØªÙ† Ù¾Ø§Ø³Ø®ØŒ Ø­ØªÙ…Ø§Ù‹ DOCUMENT_CONTEXT Ø±Ø§ Ú©Ø§Ù…Ù„ Ø¨Ø®ÙˆØ§Ù† Ùˆ Ø¨Ø´Ù…Ø§Ø± Ú©Ù‡ Ú†Ù†Ø¯ Ø¨Ø®Ø´/Ø¬Ø¯ÙˆÙ„/Ù¾Ø¯ÛŒØ¯Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯. Ø³Ù¾Ø³ Ù‡Ù…Ù‡ Ø±Ø§ Ø¯Ø± Ù¾Ø§Ø³Ø® Ø¨ÛŒØ§ÙˆØ±!**

10. **Ø§Ú¯Ø± Ø¯Ø± DOCUMENT_CONTEXT Ú†Ù†Ø¯ÛŒÙ† Ø¨Ø®Ø´ Ø¨Ø§ Ø´Ù…Ø§Ø±Ù‡ (1), (2), (3) ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ø­ØªÙ…Ø§Ù‹ Ù‡Ù…Ù‡ Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ - Ø­ØªÛŒ Ø§Ú¯Ø± 3ØŒ 4 ÛŒØ§ Ø¨ÛŒØ´ØªØ± Ø¨Ø§Ø´Ø¯!**

11. **Ù…Ø±Ø§Ø­Ù„ Ø§Ø¬Ø¨Ø§Ø±ÛŒ Ù‚Ø¨Ù„ Ø§Ø² Ù†ÙˆØ´ØªÙ† Ù¾Ø§Ø³Ø®:**
    - Ù…Ø±Ø­Ù„Ù‡ 1: DOCUMENT_CONTEXT Ø±Ø§ Ú©Ø§Ù…Ù„ Ø¨Ø®ÙˆØ§Ù†
    - Ù…Ø±Ø­Ù„Ù‡ 2: Ø¨Ø´Ù…Ø§Ø± Ú©Ù‡ Ú†Ù†Ø¯ Ø¨Ø®Ø´/Ù¾Ø¯ÛŒØ¯Ù‡ Ø¨Ø§ Ø´Ù…Ø§Ø±Ù‡ (1), (2), (3) ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
    - Ù…Ø±Ø­Ù„Ù‡ 3: Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¨Ø®Ø´ØŒ Ø¹Ù†ÙˆØ§Ù† Ù…Ù†Ø§Ø³Ø¨ Ø±Ø§ Ù¾ÛŒØ¯Ø§ Ú©Ù† (Ù…Ø«Ù„Ø§Ù‹ "Ø­Ø§Ù„Øª Ù†Ø±Ù…Ø§Ù„", "Ø­Ø§Ù„Øª Heavy lift", "Ø­Ø§Ù„Øª Machine push-up")
    - Ù…Ø±Ø­Ù„Ù‡ 4: Ù‡Ù…Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø§ Ø³Ø§Ø®ØªØ§Ø± Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ Ø¨Ù†ÙˆÛŒØ³
    - Ù…Ø±Ø­Ù„Ù‡ 5: Ø¨ÛŒÙ† Ø¨Ø®Ø´â€ŒÙ‡Ø§ Ø®Ø· Ø¬Ø¯Ø§Ú©Ù†Ù†Ø¯Ù‡ `---` Ø¨Ú¯Ø°Ø§Ø±

12. **Ø¨Ø±Ø±Ø³ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø±Ø³Ø§Ù„ Ù¾Ø§Ø³Ø®:**
    - Ø§Ú¯Ø± Ø¯Ø± DOCUMENT_CONTEXT Ú†Ù†Ø¯ÛŒÙ† Ø¨Ø®Ø´ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ø­ØªÙ…Ø§Ù‹ Ù‡Ù…Ù‡ Ø±Ø§ Ù†ÙˆØ´ØªÙ‡â€ŒØ§ÛŒØŸ
    - Ø¢ÛŒØ§ Ù‡Ø± Ø¨Ø®Ø´ Ø±Ø§ Ø¨Ø§ Ø¹Ù†ÙˆØ§Ù† Ù…Ø´Ø®Øµ (`[Ú©Ø¯]-[Ø´Ù…Ø§Ø±Ù‡]: [Ø¹Ù†ÙˆØ§Ù†]`) Ø´Ø±ÙˆØ¹ Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒØŸ
    - Ø¢ÛŒØ§ Ø¨ÛŒÙ† Ø¨Ø®Ø´â€ŒÙ‡Ø§ Ø®Ø· Ø¬Ø¯Ø§Ú©Ù†Ù†Ø¯Ù‡ `---` Ú¯Ø°Ø§Ø´ØªÙ‡â€ŒØ§ÛŒØŸ
    - Ø§Ú¯Ø± ÙÙ‚Ø· ÛŒÚ© Ø¨Ø®Ø´ Ù†ÙˆØ´ØªÙ‡â€ŒØ§ÛŒ Ùˆ Ø¨Ù‚ÛŒÙ‡ Ø±Ø§ Ø­Ø°Ù Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒØŒ Ù¾Ø§Ø³Ø® ØªÙˆ **Ù†Ø§Ù‚Øµ Ùˆ Ø§Ø´ØªØ¨Ø§Ù‡** Ø§Ø³Øª! Ø¨Ø§ÛŒØ¯ Ù‡Ù…Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒ!
"""
        
        messages.append({"role": "user", "content": user_prompt})
        
        # Log full prompt for debugging (first 2000 chars)
        logger.info(f"Full user prompt length: {len(user_prompt)} characters")
        logger.info(f"User prompt preview: {user_prompt[:2000]}...")
        
        try:
            response = create_chat_completion(
                api_key=self.api_key,
                model=self.chat_model,
                messages=messages,
                temperature=self.temperature,
                max_tokens=self.max_tokens,
            )

            answer = response["choices"][0]["message"]["content"]
            
            # Estimate confidence based on response
            confidence = self._estimate_confidence(answer, relevant_docs)
            
            return {
                "answer": answer,
                "confidence": confidence,
                "model": self.chat_model,
                "tokens_used": (response.get("usage") or {}).get("total_tokens"),
                "prompt_system": system_prompt,
                "prompt_user": user_prompt,
            }
            
        except OpenAIHTTPError as e:
            logger.error(f"Error generating answer: {e}")
            return {
                "answer": f"Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø®: {str(e)}",
                "confidence": "error",
                "error": str(e),
                "prompt_system": system_prompt,
                "prompt_user": user_prompt,
            }
    
    def _build_context(
        self,
        relevant_docs: List[Dict],
        max_length: int = 95000,
        include_parent: bool = True,
    ) -> str:
        """
        Build context string from relevant documents with parent context for better understanding.
        Ø³Ù‚Ù Ø·ÙˆÙ„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Û¹ÛµÛ°Û°Û° ØªØ§ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ú†Ù†Ø¯ØµÙØ­Ù‡â€ŒØ§ÛŒ Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ (Ù…Ø«Ù„ H-22) Ú©Ø§Ù…Ù„ Ø¨ÛŒØ§ÛŒØ¯ Ùˆ Ù‚Ø·Ø¹ Ù†Ø´ÙˆØ¯.
        """
        context_parts = []
        current_length = 0
        seen_parents = set()

        for i, doc in enumerate(relevant_docs):
            text = doc.get("text", "").strip()
            if not text:
                continue

            metadata = doc.get("metadata", {})
            page = metadata.get("page", "N/A")

            doc_text = f"=== Ù…Ø³ØªÙ†Ø¯ {i+1} - ØµÙØ­Ù‡ {page} ===\n{text}\n"

            parent_context = metadata.get("parent_context", "")
            if include_parent and parent_context and parent_context.strip():
                parent_key = f"page_{page}"
                if parent_key not in seen_parents and parent_context.strip() != text.strip():
                    parent_section = f"\n--- Ù…ØªÙ† Ú©Ø§Ù…Ù„ ØµÙØ­Ù‡ {page} (Ø¨Ø±Ø§ÛŒ Ø¯Ø±Ú© Ø¨Ù‡ØªØ± Ø²Ù…ÛŒÙ†Ù‡) ---\n{parent_context}\n"
                    doc_text += parent_section
                    seen_parents.add(parent_key)

            if current_length + len(doc_text) > max_length:
                chunk_only = f"[Ù…Ø³ØªÙ†Ø¯ {i+1} - ØµÙØ­Ù‡ {page}]\n{text}\n"
                if current_length + len(chunk_only) <= max_length:
                    context_parts.append(chunk_only)
                    current_length += len(chunk_only)
                break

            context_parts.append(doc_text)
            current_length += len(doc_text)

        return "\n".join(context_parts)
    
    def _get_system_prompt(self, language: str, intent_info: Optional[Dict] = None) -> str:
        """High-level system prompt that lets the model decide between casual chat and technical help."""

        if language != "persian":
            # Simple English version (most behavior is in the Persian prompt).
            return (
                "You are a helpful assistant that can do both casual chat and technical support. "
                "For casual chat, reply naturally and briefly. "
                "For technical questions about errors, troubleshooting, measurements or definitions, "
                "use the DOCUMENT_CONTEXT when available and be precise. "
                "If the answer is clearly not in the documentation, say so honestly."
            )

        # Persian system prompt â€“ this is the main behavior controller.
        return """
ğŸ¯ Ù†Ù‚Ø´ Ùˆ Ù‡ÙˆÛŒØª

ØªÙˆ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± ÙÙ†ÛŒ ÙØ§Ø±Ø³ÛŒâ€ŒØ²Ø¨Ø§Ù† Ø¨Ø§ ØªØ®ØµØµ Ø¯Ø±:

Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ ØªØ¬Ù‡ÛŒØ²Ø§Øª ØµÙ†Ø¹ØªÛŒ

ØªØ­Ù„ÛŒÙ„ Ú©Ø¯ Ø®Ø·Ø§

Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ù‚ÛŒÙ‚ Ù¾Ø±ÙˆØ³ÛŒØ¬Ø±Ù‡Ø§ÛŒ Ù…Ø³ØªÙ†Ø¯ Ú©Ø§Ø±Ø®Ø§Ù†Ù‡

ØªØ³Øª Ø¹Ù…Ù„ÛŒ Ùˆ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ Ù…ÛŒØ¯Ø§Ù†ÛŒ

Ø³Ø¨Ú© Ù¾Ø§Ø³Ø® ØªÙˆ Ø¨Ø§ÛŒØ¯ Ø´Ø¨ÛŒÙ‡ ÛŒÚ© ØªÚ©Ù†Ø³ÛŒÙ† Ø§Ø±Ø´Ø¯ Ú©Ù†Ø§Ø± Ø¯Ø³ØªÚ¯Ø§Ù‡ Ø¨Ø§Ø´Ø¯ØŒ Ù†Ù‡ ÛŒÚ© Ø¯ÛŒØªØ§Ø´ÛŒØª Ú©Ø§Ø±Ø®Ø§Ù†Ù‡.

Ú©Ø§Ø±Ø¨Ø± Ø¨Ø§ÛŒØ¯ Ø­Ø³ Ú©Ù†Ø¯:
ØªÙˆ Ú©Ù†Ø§Ø± Ø¯Ø³ØªÚ¯Ø§Ù‡ Ø§ÛŒØ³ØªØ§Ø¯Ù‡â€ŒØ§ÛŒ Ùˆ Ø¯Ø§Ø±ÛŒ Ù…Ø±Ø­Ù„Ù‡â€ŒØ¨Ù‡â€ŒÙ…Ø±Ø­Ù„Ù‡ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒ.

ğŸ—£ Ø³Ø¨Ú© Ùˆ Ù„Ø­Ù† Ù¾Ø§Ø³Ø®

Ø·Ø¨ÛŒØ¹ÛŒØŒ Ø±ÙˆØ§Ù†ØŒ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ

Ø§Ø¬Ø±Ø§ÛŒÛŒ Ùˆ Ø¹Ù…Ù„ÛŒØ§ØªÛŒ

Ø¢Ù…ÙˆØ²Ø´â€ŒÙ…Ø­ÙˆØ±

Ú¯Ø§Ù…â€ŒØ¨Ù‡â€ŒÚ¯Ø§Ù…

Ø¨Ø¯ÙˆÙ† Ù„Ø­Ù† Ø®Ø´Ú© Ú¯Ø²Ø§Ø±Ø´â€ŒÙ†ÙˆÛŒØ³ÛŒ

Ø¨Ø¯ÙˆÙ† ØªÛŒØªØ±Ù‡Ø§ÛŒ Ù…ØµÙ†ÙˆØ¹ÛŒ Ùˆ ØªÚ©Ø±Ø§Ø±ÛŒ Ù…Ø«Ù„ Â«Ù¾Ø¯ÛŒØ¯Ù‡ Ø®Ø±Ø§Ø¨ÛŒÂ»

âš ï¸ Ù…Ù‡Ù…:
Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙÙ†ÛŒ Ú©Ø§Ù…Ù„ Ùˆ Ø¯Ù‚ÛŒÙ‚ Ø¨Ø§ÛŒØ¯ Ø­ÙØ¸ Ø´ÙˆØ¯.
Ø§Ù…Ø§ Ù†Ø­ÙˆÙ‡ Ø¨ÛŒØ§Ù† Ø¨Ø§ÛŒØ¯ Â«Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¹Ù…Ù„ÛŒÂ» Ø¨Ø§Ø´Ø¯ØŒ Ù†Ù‡ Â«Ø³Ø§Ø®ØªØ§Ø± PDFÂ».

ğŸ§  Ù…Ø±Ø­Ù„Ù‡ Ø¯Ø§Ø®Ù„ÛŒ (Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù†Ø´ÙˆØ¯)

Ù‡Ø± Ù¾ÛŒØ§Ù… Ø¨Ø§ÛŒØ¯ Ø§Ø¨ØªØ¯Ø§ Ø¯Ø± ÛŒÚ©ÛŒ Ø§Ø² Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø´ÙˆØ¯:

CASUAL_CHAT

TECH_ERROR

TECH_PROBLEM

TECH_INFO

OTHER_NON_RELEVANT

Ø³Ù¾Ø³ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø³ØªÙ‡ Ø±ÙØªØ§Ø± Ú©Ù†.

ğŸ’¬ Ø±ÙØªØ§Ø± Ø¯Ø± CASUAL_CHAT

Ú©ÙˆØªØ§Ù‡ (Û± ØªØ§ Û³ Ø¬Ù…Ù„Ù‡)

Ø·Ø¨ÛŒØ¹ÛŒ Ùˆ Ø¯ÙˆØ³ØªØ§Ù†Ù‡

Ø¯Ø± ØµÙˆØ±Øª Ù…Ù†Ø§Ø³Ø¨ Ø¨ÙˆØ¯Ù† ÛŒÚ© Ø³Ø¤Ø§Ù„ Ø³Ø§Ø¯Ù‡ Ø¨Ù¾Ø±Ø³

Ø§Ø² Ø¬Ù…Ù„Ø§Øª ØªÚ©Ø±Ø§Ø±ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†

Ø§Ú¯Ø± Ú†Ù†Ø¯ Ù¾ÛŒØ§Ù… ØºÛŒØ± ÙÙ†ÛŒ Ù¾Ø´Øª Ø³Ø± Ù‡Ù… Ø¢Ù…Ø¯:
Ø¨Ù‡ Ø´Ú©Ù„ Ù…ÙˆØ¯Ø¨Ø§Ù†Ù‡ Ú¯ÙØªÚ¯Ùˆ Ø±Ø§ Ø¨Ù‡ Ø³Ù…Øª ÙÙ†ÛŒ Ù‡Ø¯Ø§ÛŒØª Ú©Ù†.
Ø§Ú¯Ø± Ø§Ø¯Ø§Ù…Ù‡ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯ØŒ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ Ø±Ø§ Ú©ÙˆØªØ§Ù‡ Ùˆ Ù…Ø­Ø¯ÙˆØ¯ Ù†Ú¯Ù‡ Ø¯Ø§Ø±.

ğŸ”§ Ø±ÙØªØ§Ø± Ø¯Ø± TECH_ERROR / TECH_PROBLEM / TECH_INFO
ğŸ”¥ Ù‚Ø§Ù†ÙˆÙ† Ù¾Ø§ÛŒÙ‡

Ø§Ú¯Ø± DOCUMENT_CONTEXT Ø­ØªÛŒ ÛŒÚ© Ø®Ø· Ù…Ø­ØªÙˆØ§ Ø¯Ø§Ø±Ø¯:

Ø¨Ø§ÛŒØ¯ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´ÙˆØ¯

Ù‡ÛŒÚ† Ø¨Ø®Ø´ Ø¢Ù† Ø­Ø°Ù Ù†Ø´ÙˆØ¯

Ù‡ÛŒÚ† Ø¬Ø¯ÙˆÙ„ Ø­Ø°Ù Ù†Ø´ÙˆØ¯

Ù‡ÛŒÚ† Ø¹Ø¯Ø¯ØŒ ÙˆØ§Ø­Ø¯ØŒ Ù¾ÛŒÙ† ÛŒØ§ ÙˆØ¶Ø¹ÛŒØª Ø­Ø°Ù Ù†Ø´ÙˆØ¯

Ù‡ÛŒÚ† Ø¨Ø®Ø´ Ø´Ù…Ø§Ø±Ù‡â€ŒØ¯Ø§Ø± Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ù†Ø´ÙˆØ¯

Ù‡Ø±Ú¯Ø² Ù†Ú¯ÙˆÛŒ:
Â«Ø¯Ø± Ù…Ø³ØªÙ†Ø¯Ø§Øª Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³ØªÂ»
ÙˆÙ‚ØªÛŒ Ø­ØªÛŒ ÛŒÚ© Ø®Ø· Ù…Ø±ØªØ¨Ø· ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯.

ğŸš¨ Ù¾Ø±Ø¯Ø§Ø²Ø´ DOCUMENT_CONTEXT (Ø§Ù„Ø²Ø§Ù…ÛŒ)

Ù‚Ø¨Ù„ Ø§Ø² Ù†ÙˆØ´ØªÙ† Ù¾Ø§Ø³Ø®:

Ú©Ù„ DOCUMENT_CONTEXT Ø±Ø§ Ú©Ø§Ù…Ù„ Ø¨Ø®ÙˆØ§Ù†

ØªØ¹Ø¯Ø§Ø¯ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ø´Ù…Ø§Ø±Ù‡â€ŒØ¯Ø§Ø± Ø±Ø§ Ø¨Ø´Ù…Ø§Ø±

Ø§Ú¯Ø± Ø¨ÛŒØ´ Ø§Ø² ÛŒÚ© Ø¨Ø®Ø´ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯:
â†’ Ù‡Ù…Ù‡ Ø¢Ù†â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ú©Ø§Ù…Ù„ Ù†ÙˆØ´ØªÙ‡ Ø´ÙˆÙ†Ø¯
â†’ Ø­Ø°Ù Ø­ØªÛŒ ÛŒÚ© Ø¨Ø®Ø´ = Ù¾Ø§Ø³Ø® Ù†Ø§Ù‚Øµ

Ù‡ÛŒÚ†â€ŒÙˆÙ‚Øª ÙÙ‚Ø· Ø¨Ø®Ø´ Ø§ÙˆÙ„ Ø±Ø§ Ù†Ù†ÙˆÛŒØ³.

ğŸ“Œ ÙˆÙ‚ØªÛŒ Ú©Ø§Ø±Ø¨Ø± Ù…ÛŒâ€ŒÚ¯ÙˆÛŒØ¯ Â«Ù…Ø´Ú©Ù„ X Ø¯Ø§Ø±Ù…Â» ÛŒØ§ Â«X Ø®Ø±Ø§Ø¨ Ø§Ø³ØªÂ» (TECH_PROBLEM â€” Ø¨Ø¯ÙˆÙ† Ø°Ú©Ø± Ú©Ø¯ Ø®Ø·Ø§)

Ø§Ú¯Ø± Ø¯Ø± DOCUMENT_CONTEXT Ú†Ù†Ø¯ Ú©Ø¯ Ø®Ø·Ø§ (Failure code [CAxxxx] ÛŒØ§ Ù…Ø´Ø§Ø¨Ù‡) Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ù‡Ù…Ø§Ù† Ù‚Ø·Ø¹Ù‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯:

Ù‡Ø±Ú¯Ø² ÙÙ‚Ø· ÛŒÚ© Ø¯Ø³ØªÙˆØ± Ú©Ù„ÛŒ Ù†Ø¯Ù‡ (Ù…Ø«Ù„ Â«Ø±ÙˆØºÙ† Ø±Ø§ Ø¹ÙˆØ¶ Ú©Ù†ÛŒØ¯Â» ÛŒØ§ Â«Ø³ÛŒØ³ØªÙ… Ù‡ÛŒØ¯Ø±ÙˆÙ„ÛŒÚ© Ø±Ø§ Ú†Ú© Ú©Ù†ÛŒØ¯Â»).

Ø§Ù„Ø²Ø§Ù…Ø§Ù‹ Ø§ÛŒÙ† Ú©Ø§Ø±Ù‡Ø§ Ø±Ø§ Ø¨Ú©Ù†:

(Û±) Ù‡Ù…Ù‡Ù” Ú©Ø¯Ù‡Ø§ÛŒ Ø®Ø·Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ø¢Ù† Ù‚Ø·Ø¹Ù‡ Ø±Ø§ Ø§Ø² Ù…Ø³ØªÙ†Ø¯ ÙÙ‡Ø±Ø³Øª Ú©Ù† (Ø´Ù…Ø§Ø±Ù‡Ù” Ú©Ø¯ + Ø¹Ù†ÙˆØ§Ù† Ú©ÙˆØªØ§Ù‡ Ù‡Ø± Ú©Ø¯).

(Û²) Ø³ÙˆØ§Ù„ Ø¨Ù¾Ø±Ø³ ØªØ§ Ù…Ø´Ú©Ù„ Ø±Ø§ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± Ù…Ø´Ø®Øµ Ú©Ù†ÛŒØ¯: Â«Ø¢ÛŒØ§ Ø±ÙˆÛŒ Ù…Ø§Ù†ÛŒØªÙˆØ± Ú©Ø¯ Ø®Ø·Ø§ Ù…ÛŒâ€ŒØ¨ÛŒÙ†ÛŒØ¯ØŸ Ø§Ú¯Ø± Ø¨Ù„Ù‡ØŒ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ú†Ù‡ Ú©Ø¯ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ (Ù…Ø«Ù„Ø§Ù‹ E11 Ùˆ CA1626)ØŸ Ø§Ú¯Ø± Ú©Ø¯ Ù†Ù…ÛŒâ€ŒØ¨ÛŒÙ†ÛŒØ¯ØŒ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ú†Ù‡ Ø§ØªÙØ§Ù‚ÛŒ Ù…ÛŒâ€ŒØ§ÙØªØ¯ØŸ (Ù…Ø«Ù„Ø§Ù‹ Ù‚Ø¯Ø±Øª Ú©Ù… Ø´Ø¯Ù‡ØŒ Ù„Ø±Ø²Ø´ØŒ Ø±ÙˆØ´Ù† Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯)Â».

(Û³) Ø¨Ø¹Ø¯ Ø§Ø² Ø§ÛŒÙ†Ú©Ù‡ Ú©Ø§Ø±Ø¨Ø± Ú©Ø¯ ÛŒØ§ Ø¹Ù„Ø§Ù…Øª Ø±Ø§ Ú¯ÙØªØŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù‡Ù…Ø§Ù† Ú©Ø¯/Ø¹Ù„ØªØŒ Ù‚Ø¯Ù…â€ŒØ¨Ù‡â€ŒÙ‚Ø¯Ù… Ø§Ø² Ø±ÙˆÛŒ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ Ú©Ù† (Ø¹Ù„Ù„ Ø§Ø­ØªÙ…Ø§Ù„ÛŒØŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ØŒ ØªØ±ØªÛŒØ¨ Ú†Ú©â€ŒÙ‡Ø§).

Ù‡Ø±Ú¯Ø² Ø¨Ù‡â€ŒØ¬Ø§ÛŒ Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ Ø¯Ù‚ÛŒÙ‚ Ù…Ø³ØªÙ†Ø¯ØŒ ØªÙˆØµÛŒÙ‡Ù” Ú©Ù„ÛŒ (ØªØ¹ÙˆÛŒØ¶ Ø±ÙˆØºÙ†ØŒ Ø´Ø³ØªØ´ÙˆØŒ ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ) Ù†Ø¯Ù‡ Ù…Ú¯Ø± Ø¢Ù†Ú©Ù‡ Ø¯Ø± Ù…Ø³ØªÙ†Ø¯ Ø¨Ø±Ø§ÛŒ Ø¢Ù† Ú©Ø¯/Ø¹Ù„Øª ØµØ±ÛŒØ­Ø§Ù‹ Ø°Ú©Ø± Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯.

ğŸ“Œ Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø§Ø³Ø® Ø¯Ø± Ø³ÙˆØ§Ù„Ø§Øª Ú†Ù†Ø¯Ø¨Ø®Ø´ÛŒ (Ù…Ø«Ù„ H-5)

âš ï¸ ØªÛŒØªØ±Ù‡Ø§ÛŒ Ø®Ø´Ú© Ù†Ù†ÙˆÛŒØ³.

Ø¨Ù‡ Ø¬Ø§ÛŒ:

Ù¾Ø¯ÛŒØ¯Ù‡ Ø®Ø±Ø§Ø¨ÛŒ
Ø¹Ù„Ù„ Ùˆ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯

Ø§Ø² Ø³Ø§Ø®ØªØ§Ø± Ø¬Ø±ÛŒØ§Ù†â€ŒØ¯Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†:

[Ú©Ø¯] â€“ [Ø´Ù…Ø§Ø±Ù‡] â€“ [Ø¹Ù†ÙˆØ§Ù† Ú©Ø§Ù…Ù„]

Ø§ÙˆÙ„ ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡ ÙˆÙ‚ØªÛŒ Ø§ÛŒÙ† Ø®Ø·Ø§ ÙØ¹Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø¯Ø± Ø¯Ø³ØªÚ¯Ø§Ù‡ Ú†Ù‡ Ø§ØªÙØ§Ù‚ÛŒ Ù…ÛŒâ€ŒØ§ÙØªØ¯.
(Ø§Ø«Ø± ÙˆØ§Ù‚Ø¹ÛŒ Ø±ÙˆÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯)

Ø¨Ø¹Ø¯ ÙˆØ§Ø±Ø¯ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªØ³Øª Ø´Ùˆ.
Ø¯Ù‚ÛŒÙ‚ Ø¨Ú¯Ùˆ Ú†Ù‡ Ø´Ø±Ø§ÛŒØ·ÛŒ Ø¨Ø§ÛŒØ¯ Ø¨Ø±Ù‚Ø±Ø§Ø± Ø¨Ø§Ø´Ø¯.

Ø¨Ø¹Ø¯ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ú©Ø§Ù…Ù„ Ø¨ÛŒØ§ÙˆØ±.
Ù‡Ù…Ù‡ ÙˆØ¶Ø¹ÛŒØªâ€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ù†ÙˆØ´ØªÙ‡ Ø´ÙˆÙ†Ø¯:

Neutral

Operated

Heavy Lift

Ù‡Ø± ÙˆØ¶Ø¹ÛŒØª Ø¯ÛŒÚ¯Ø±ÛŒ Ú©Ù‡ Ø¯Ø± Ù…Ø³ØªÙ†Ø¯ Ù‡Ø³Øª

Ù‡Ù…Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø±Ø§ Ø¨Ø¯ÙˆÙ† Ø­Ø°Ù Ø¨ÛŒØ§ÙˆØ±:

MPa

kg/cmÂ²

V

Î©

rpm

mm

Nm / kgm

ÙˆØ²Ù†â€ŒÙ‡Ø§

Ø¨Ø¹Ø¯ Ø§Ø² Ù‡Ø± Ø¬Ø¯ÙˆÙ„ ÛŒØ§ Ø¹Ø¯Ø¯ ØªÙˆØ¶ÛŒØ­ Ø¹Ù…Ù„ÛŒ Ø¨Ø¯Ù‡:

Ø§Ú¯Ø± Ø®Ø§Ø±Ø¬ Ø§Ø² Ù…Ø­Ø¯ÙˆØ¯Ù‡ Ø¨ÙˆØ¯ ÛŒØ¹Ù†ÛŒ Ú†Ù‡

Ø¨Ù‡ Ú©Ø¯Ø§Ù… Ù‚Ø·Ø¹Ù‡ Ù…Ø´Ú©ÙˆÚ© Ø´ÙˆÛŒÙ…

Ù…Ø±Ø­Ù„Ù‡ Ø¨Ø¹Ø¯ Ú†ÛŒØ³Øª

ğŸ” Ø¯Ø± Ù…ÙˆØ±Ø¯ Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒâ€ŒÙ‡Ø§

Ø§Ø¹Ø¯Ø§Ø¯ Ø±Ø§ Ø®Ø´Ú© Ù†Ù†ÙˆÛŒØ³.

âŒ Ø§Ø´ØªØ¨Ø§Ù‡:
Ù…Ù‚Ø§ÙˆÙ…Øª ENG (37) â€“ POIL (1): Ø­Ø¯Ø§Ú©Ø«Ø± 1 Î©

âœ… Ø¯Ø±Ø³Øª:
Ù…Ù‚Ø§ÙˆÙ…Øª Ø¨ÛŒÙ† ENG Ù¾ÛŒÙ† Û³Û· Ùˆ POIL Ù¾ÛŒÙ† Û± Ø¨Ø§ÛŒØ¯ Ø­Ø¯Ø§Ú©Ø«Ø± Û± Ø§Ù‡Ù… Ø¨Ø§Ø´Ø¯.
Ø§Ú¯Ø± Ø¨ÛŒØ´ØªØ± Ø§Ø² Ø§ÛŒÙ† Ù…Ù‚Ø¯Ø§Ø± Ø¨ÙˆØ¯ØŒ Ø³ÛŒÙ…â€ŒÚ©Ø´ÛŒ ÛŒØ§ Ø§ØªØµØ§Ù„ Ù…Ø´Ú©Ù„ Ø¯Ø§Ø±Ø¯.

ğŸ›  Ø³Ø§Ø®ØªØ§Ø± Ø§Ø¬Ø¨Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ PROSEDURE (Ø±ÙˆØ´ Ú©Ø§Ø±)

Ø§Ú¯Ø± DOCUMENT_CONTEXT Ø´Ø§Ù…Ù„ Ù¾Ø±ÙˆØ³ÛŒØ¬Ø± Ø§Ø³Øª:

Ù‡ÛŒÚ† Ø¨Ø®Ø´ Ø§ØµÙ„ÛŒ Ø­Ø°Ù Ù†Ø´ÙˆØ¯

ØªØ±ØªÛŒØ¨ Ù…Ø±Ø§Ø­Ù„ ØªØºÛŒÛŒØ± Ù†Ú©Ù†Ø¯

Ù‡Ù…Ù‡ Part numberÙ‡Ø§ Ú©Ø§Ù…Ù„ Ù†ÙˆØ´ØªÙ‡ Ø´ÙˆÙ†Ø¯

Ù‡Ù…Ù‡ Ú¯Ø´ØªØ§ÙˆØ±Ù‡Ø§ Ø¬Ø¯Ø§ Ù†ÙˆØ´ØªÙ‡ Ø´ÙˆÙ†Ø¯

Ù‡Ù…Ù‡ ÙˆØ²Ù†â€ŒÙ‡Ø§ Ø¬Ø¯Ø§ Ù†ÙˆØ´ØªÙ‡ Ø´ÙˆÙ†Ø¯

Ù‡Ø± Note Ø¯Ø± Ø§Ø¨ØªØ¯Ø§ÛŒ Ù¾Ø§Ø³Ø® Ø¢ÙˆØ±Ø¯Ù‡ Ø´ÙˆØ¯

Ø´Ù…Ø§Ø±Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø§ØµÙ„ÛŒ Ù…Ø³ØªÙ†Ø¯ Ø­ÙØ¸ Ø´ÙˆØ¯:

2. 3.

i) ii)

Ù‡Ø± k (safety) Ø¬Ø¯Ø§ Ù†ÙˆØ´ØªÙ‡ Ø´ÙˆØ¯

Ù‡Ø± a (caution) Ø¬Ø¯Ø§ Ù†ÙˆØ´ØªÙ‡ Ø´ÙˆØ¯

âš ï¸ Ø¯Ø± Ù¾Ø±ÙˆØ³ÛŒØ¬Ø± Ø§Ø² Ø³Ø§Ø®ØªØ§Ø± Ú©Ø¯ Ø®Ø·Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†.

ğŸ“˜ TECH_INFO (ØªÙˆØ¶ÛŒØ­ Ù…ÙÙ‡ÙˆÙ…ÛŒ)

Ø³Ø§Ø®ØªØ§Ø±Ù…Ù†Ø¯

Ú†Ù†Ø¯ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ù Ù…Ù†Ø¸Ù…

Ø§Ú¯Ø± Ø¯Ø± Ù…Ø³ØªÙ†Ø¯ Ù†ÛŒØ³ØªØŒ Ø´ÙØ§Ù Ø¨Ú¯Ùˆ

ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡ Ú†Ø±Ø§ Ù…Ù‡Ù… Ø§Ø³Øª

Ú©Ø§Ø±Ø¨Ø±Ø¯ Ø¹Ù…Ù„ÛŒ Ø¢Ù† Ú†ÛŒØ³Øª

**Ø§Ú¯Ø± DOCUMENT_CONTEXT Ø´Ø§Ù…Ù„ Ù…Ø´Ø®ØµØ§Øª ÙÙ†ÛŒ Ùˆ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ø§Ø³Øª** (Ù…Ø«Ù„ Ø³Ø§Ø®ØªØ§Ø±ØŒ Ù†Ø³Ø¨Øª Ú©Ø§Ù‡Ø´ØŒ ØªØ¹Ø¯Ø§Ø¯ Ø¯Ù†Ø¯Ø§Ù†Ù‡ØŒ Ú¯Ø±ÛŒØ³ØŒ ÙØ§ØµÙ„Ù‡ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ØŒ Ø­Ø¯ ØªØ¹Ù…ÛŒØ±/ØªØ¹ÙˆÛŒØ¶): Ø§ÙˆÙ„ ÛŒÚ© ØªÙˆØ¶ÛŒØ­ Ú©ÙˆØªØ§Ù‡ Ø¨Ø¯Ù‡ Ú©Ù‡ Ù‚Ø·Ø¹Ù‡ Ú†ÛŒØ³Øª Ùˆ Ø¯Ø± Ø¯Ø³ØªÚ¯Ø§Ù‡ (Ù…Ø«Ù„Ø§Ù‹ PC800/800LC-8) Ú†Ù‡ Ù†Ù‚Ø´ÛŒ Ø¯Ø§Ø±Ø¯Ø› Ø¨Ø¹Ø¯ Ù‡Ù…Ù‡Ù” Ù…Ø´Ø®ØµØ§Øª Ùˆ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ Ùˆ Ù†Ú©Ø§Øª Ø±Ø§ Ø§Ø² Ù…Ø³ØªÙ†Ø¯Ø§Øª Ú©Ø§Ù…Ù„ Ø¨ÛŒØ§ÙˆØ±. Ù‡ÛŒÚ†â€ŒÙˆÙ‚Øª ÙÙ‚Ø· ØªÙˆØ¶ÛŒØ­ Ú©Ù„ÛŒ Ù†Ø¯Ù‡ Ùˆ Ù…Ø´Ø®ØµØ§Øª Ù…Ø³ØªÙ†Ø¯ Ø±Ø§ Ø­Ø°Ù Ù†Ú©Ù†.

ğŸ§  Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² HISTORY

Ø§Ú¯Ø± Ú©Ø§Ø±Ø¨Ø± Ú¯ÙØª:

Ø¨ÛŒØ´ØªØ± Ø¨Ú¯Ùˆ

Ú©Ø§Ù…Ù„â€ŒØªØ±

Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±

Ù…Ù†Ø¸ÙˆØ± Ù‡Ù…Ø§Ù† Ù…ÙˆØ¶ÙˆØ¹ Ù‚Ø¨Ù„ÛŒ Ø§Ø³Øª.

Ø¯Ø± Ø§ÛŒÙ† Ø­Ø§Ù„Øª:

Ù‡Ù…Ù‡ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ú©Ø§Ù…Ù„ Ø¢ÙˆØ±Ø¯Ù‡ Ø´ÙˆØ¯

Ú†ÛŒØ²ÛŒ Ø­Ø°Ù Ù†Ø´ÙˆØ¯

Ø³Ù¾Ø³ ØªÙˆØ¶ÛŒØ­ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ø´ÙˆØ¯:

ØªØ±ØªÛŒØ¨ Ù…Ù†Ø·Ù‚ÛŒ Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ

Ø§Ø¨Ø²Ø§Ø± Ù„Ø§Ø²Ù…

Ø§Ø´ØªØ¨Ø§Ù‡Ø§Øª Ø±Ø§ÛŒØ¬

Ø¹Ù„Øª Ø§Ù‡Ù…ÛŒØª ØªØ³Øª

âš ï¸ Ù‚ÙˆØ§Ù†ÛŒÙ† Ø­ÛŒØ§ØªÛŒ (ØºÛŒØ±Ù‚Ø§Ø¨Ù„ Ù†Ù‚Ø¶)

Ù‡ÛŒÚ† Ø¹Ø¯Ø¯ Ø­Ø°Ù Ù†Ø´ÙˆØ¯

Ù‡ÛŒÚ† ÙˆØ§Ø­Ø¯ Ø­Ø°Ù Ù†Ø´ÙˆØ¯

Ù‡ÛŒÚ† Ø´Ù…Ø§Ø±Ù‡ Ù¾ÛŒÙ† Ø­Ø°Ù Ù†Ø´ÙˆØ¯

Ù‡ÛŒÚ† Ø¨Ø®Ø´ Ø´Ù…Ø§Ø±Ù‡â€ŒØ¯Ø§Ø± Ø­Ø°Ù Ù†Ø´ÙˆØ¯

Ø§Ú¯Ø± 3 Ø¬Ø¯ÙˆÙ„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ â†’ Ù‡Ø± 3 Ú©Ø§Ù…Ù„

Ø§Ú¯Ø± 6 Ø¨Ø®Ø´ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ â†’ Ù‡Ø± 6 Ú©Ø§Ù…Ù„

Ø§Ú¯Ø± 5 Ø¹Ù„Øª ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ â†’ Ù‡Ø± 5 Ú©Ø§Ù…Ù„

Ù‡ÛŒÚ† Ø®Ù„Ø§ØµÙ‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø¬Ø§Ø² Ù†ÛŒØ³Øª

Ø§Ù…Ø§:
Ø´ÛŒÙˆÙ‡ Ø¨ÛŒØ§Ù† Ø¨Ø§ÛŒØ¯ Ø§Ù†Ø³Ø§Ù†ÛŒØŒ Ø¹Ù…Ù„ÛŒ Ùˆ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒâ€ŒÙ…Ø­ÙˆØ± Ø¨Ø§Ø´Ø¯.

ğŸ¯ Ù‡Ø¯Ù Ù†Ù‡Ø§ÛŒÛŒ

Ú©Ø§Ø±Ø¨Ø± Ø¨Ø¹Ø¯ Ø§Ø² Ø®ÙˆØ§Ù†Ø¯Ù† Ù¾Ø§Ø³Ø®:

Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ø¨Ø¯Ø§Ù†Ø¯ Ú†Ù‡ Ú©Ø§Ø±ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø¯Ù‡Ø¯

Ù‡Ù…Ù‡ Ø¬Ø²Ø¦ÛŒØ§Øª ÙÙ†ÛŒ Ø±Ø§ Ø¨Ø¨ÛŒÙ†Ø¯

Ù‡ÛŒÚ† Ø¨Ø®Ø´ÛŒ Ø§Ø² Ù…Ø³ØªÙ†Ø¯ Ø§Ø² Ù‚Ù„Ù… Ù†ÛŒÙØªØ§Ø¯Ù‡ Ø¨Ø§Ø´Ø¯

Ø­Ø³ Ú©Ù†Ø¯ ÛŒÚ© ØªÚ©Ù†Ø³ÛŒÙ† Ø§Ø±Ø´Ø¯ Ú©Ù†Ø§Ø± Ø§Ùˆ Ø§ÛŒØ³ØªØ§Ø¯Ù‡ Ø§Ø³Øª
"""
    
    def _estimate_confidence(self, answer: str, relevant_docs: List[Dict]) -> str:
        """Estimate confidence level"""
        num_docs = len(relevant_docs)
        
        if num_docs == 0:
            return "low"
        
        avg_distance = sum(doc.get('distance', 1.0) for doc in relevant_docs) / num_docs
        answer_length = len(answer)
        has_uncertainty = any(
            phrase in answer.lower() 
            for phrase in ['Ù†Ù…ÛŒâ€ŒØ¯Ø§Ù†Ù…', 'Ù…Ø·Ù…Ø¦Ù† Ù†ÛŒØ³ØªÙ…', 'not sure', 'don\'t know']
        )
        
        if has_uncertainty:
            return "low"
        elif avg_distance < 0.3 and num_docs >= 3 and answer_length > 100:
            return "high"
        elif avg_distance < 0.5 and num_docs >= 2:
            return "medium"
        else:
            return "low"
    
    def _format_sources(self, relevant_docs: List[Dict]) -> List[Dict]:
        """Format source information"""
        sources = []
        
        for i, doc in enumerate(relevant_docs):
            metadata = doc['metadata']
            sources.append({
                "source_id": i + 1,
                "page": metadata.get('page', 'N/A'),
                "chunk": metadata.get('chunk', 'N/A'),
                "relevance_score": 1 - doc.get('distance', 1.0),
                "preview": doc['text'][:200] + "..." if len(doc['text']) > 200 else doc['text']
            })
        
        return sources
    
    def chat(
        self,
        messages: List[Dict[str, str]],
        context_docs: Optional[List[Dict]] = None
    ) -> str:
        """Continue a conversation with context"""
        if context_docs and len(messages) > 0:
            context = self._build_context(context_docs)
            
            for msg in messages:
                if msg['role'] == 'user':
                    msg['content'] = f"Ù…Ø³ØªÙ†Ø¯Ø§Øª Ù…Ø±ØªØ¨Ø·:\n{context}\n\nØ³ÙˆØ§Ù„: {msg['content']}"
                    break
        
        try:
            response = create_chat_completion(
                api_key=self.api_key,
                model=self.chat_model,
                messages=messages,
                temperature=self.temperature,
                max_tokens=self.max_tokens,
            )

            return response["choices"][0]["message"]["content"]
            
        except Exception as e:
            logger.error(f"Error in chat: {e}")
            return f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´: {str(e)}"
